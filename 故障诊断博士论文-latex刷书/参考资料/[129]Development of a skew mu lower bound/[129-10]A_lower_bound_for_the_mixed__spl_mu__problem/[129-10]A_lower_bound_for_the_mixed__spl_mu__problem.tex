\documentclass[10pt]{article}
\usepackage{researchnotes}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan,}
\urlstyle{same}

\author{Peter M. Young and John C. Doyle}
\date{}


\begin{document}
\maketitle

\section*{A Lower Bound for the Mixed $\boldsymbol{\mu}$ Problem}


\begin{abstract}
The mixed $\mu$ problem has been shown to be NP hard so that exact analysis appears intractable. Our goal then is to exploit the problem structure so as to develop a polynomial time algorithm that approximates $\mu$ and usually gives good answers. To this end it is shown that $\mu$ is equivalent to a real eigenvalue maximization problem, and a power algorithm is developed to tackle this problem. The algorithm not only provides a lower bound for $\mu$ but has the property that $\mu$ is (almost) always an equilibrium point of the algorithm.
\end{abstract}

\begin{researchnote}[author=JC, date=2025-10-23]
    æœ¬æ–‡ä¸»è¦ä»‹ç»äº†ï¼šåŒæ—¶åŒ…å«å®å—å’Œå¤å—çš„mixed-\(\mu\)çš„ä¸‹ç•Œç®—æ³•
    
    æŠŠ$\mu$çš„ä¸‹ç•Œä¸ä¸€ä¸ªâ€œå®è°±åŠå¾„æœ€å¤§åŒ–â€ç´§å¯†å…³è”

\end{researchnote}

Index Terms-Computational methods, control system analysis, robust control, stability analysis, structured singular value.

\section*{I. Introduction}
Computation schemes for the complex $\mu$ problem, based on upper and lower bounds [1], [2], are now well developed, and software is commercially available as part of the $\mu$-Tools toolbox [3]. The mixed case, however, is a fundamentally more difficult problem and is much less understood. An upper bound for the general mixed $\mu$ problem was presented by Fan et al. [4] involving a minimization problem on the eigenvalues of a Hermitian matrix, and a practical scheme to compute this upper bound has recently been developed [5]. This paper addresses the problem of computing a lower bound for $\mu$ in the mixed case.

We begin with some preliminaries in Section II. It is known that the mixed $\mu$ problem is nonconvex and NP hard [6] so that, except for small problems or special cases, one cannot expect to compute exact solutions without an entirely unacceptable amount of computation. Nevertheless, we would like to quickly find approximate solutions to the problem. This motivates the power iteration approach taken in the paper. Previous work on complex $\mu$ problems has shown that power iterations are fast, seem to have some nice global properties, and give good answers most of the time. Of course we will not be able to provide guarantees about the global properties of our solution since the problem we are trying to solve is NP hard.

It is shown in Section III that mixed $\mu$ can be obtained as the result of a (nonconcave) real eigenvalue maximization. Sections IV-VI present several important theoretical characterizations of the mixed $\mu$ problem, including the generalization of the $\mu$ decomposition to the mixed case in Section V. This leads to the development of a power algorithm to compute a lower bound for the mixed $\mu$ problem which is presented in Section VI. The algorithm performance is very encouraging, both in terms of accuracy of the resulting bound and computational efficiency, and this is briefly discussed in Section VII.

\section*{II. Notation and Preliminaries}
For any square complex matrix $M$, we denote the complex conjugate transpose by $M^{*}$. The largest singular value and the spectral radius are denoted by $\bar{\sigma}(M)$ and $\rho(M)$, respectively. The real spectral radius is defined as $\rho_{R}(M)= \max \{|\lambda|: \lambda$ is a real eigenvalue of $M\}$, with $\rho_{R}(M)=0$ if $M$ has no real eigenvalues. For any complex vector $x$, then $x^{T}$ denotes the transpose, $x^{*}$ the complex conjugate transpose, $|x|$ the Euclidean norm, and $|x|_{\infty}$ the infinity norm.

The definition of the structured singular value, $\mu$, is dependent upon the underlying block structure of the uncertainties, which is defined as follows. Given a matrix $M \in \mathcal{C}^{n \times n}$ and three nonnegative integers $m_{r}, m_{c}$, and $m_{C}$ with $m \doteq m_{r}+m_{c}+m_{C} \leq n$, \hl{the block structure $\mathcal{K}\left(m_{r}, m_{c}, m_{C}\right)$ }is an $m$-tuple of positive integerså—ç»“æ„ï¼Œæ­£æ•´æ•°ç»„æˆçš„må…ƒç»„ï¼Œç”¨æ¥å¯¹ä¸ç¡®å®šå—è®¡æ•°


\begin{equation*}
\mathcal{K}=\left(k_{1}, \cdots, k_{m_{r}}, k_{m_{r}+1}, \cdots, k_{m_{r}+m_{c}}, k_{m_{r}+m_{c}+1}, \cdots, k_{m}\right) \tag{1}
\end{equation*}

\hl{ç»´åº¦å…¼å®¹ï¼š$\sum_{i=1}^{m} k_{i}=n$ï¼Œå’Œ$M$}\\
where we require $\sum_{i=1}^{m} k_{i}=n$ so these dimensions are compatible with $M$. This now determines the set of allowable perturbations, namely define
\\\hl{æ‰°åŠ¨çŸ©é˜µçš„é›†åˆ$X_{\mathcal{K}}$ï¼šæ˜¯å—å¯¹è§’çš„ï¼Œå®é‡å¤æ ‡é‡å—ã€å¤é‡å¤æ ‡é‡å—ã€å…¨å¤å—}
\[
\begin{array}{r}
X_{\mathcal{K}}=\left\{\Delta = \text { block diag } \left(\delta_{1}^{r} I_{k_{1}}, \cdots, \delta_{m_{r}}^{r} I_{k_{m_{r}}}, \delta_{1}^{c} I_{k_{m_{r}+1}}, \cdots\right.\right. \\
\left.\delta_{m_{c}}^{c} I_{k_{m_{r}+m_{c}}}, \Delta_{1}^{C}, \cdots, \Delta_{m_{C}}^{C}\right): \\
\left.\delta_{i}^{r} \in \mathcal{R}, \delta_{i}^{c} \in \mathcal{C}, \Delta_{i}^{C} \in \mathcal{C}^{k_{m_{r}+m_{c}+i} \times k_{m_{r}+m_{c}+i}}\right\} . \tag{2}
\end{array}
\]

Note that $X_{\kappa} \subset \mathcal{C}^{n \times n}$ and that this block structure is sufficiently general to allow for repeated real scalars, repeated complex scalars, and full complex blocks. Note also that the full complex blocks need not be square, but we restrict them as such for notational convenience. The purely complex case corresponds to $m_{r}=0$ and the purely real case to $m_{c}=m_{C}=0$.

\textbf{Definition 1 [1]}: The structured singular value, $\mu_{\mathcal{K}}(M)$, of a matrix $M \in \mathcal{C}^{n \times n}$ with respect to a block structure $\mathcal{K}\left(m_{r}, m_{c}, m_{C}\right)$ is defined as
\begin{equation*}
\mu_{\mathcal{K}}(M)=\left(\min _{\Delta \in X_{\mathcal{K}}}\{\bar{\sigma}(\Delta): \operatorname{det}(I-\Delta M)=0\}\right)^{-1} \tag{3}
\end{equation*}
\begin{researchnote}[author=JC, date=2025-10-23]
    åœ¨å…è®¸çš„ä¸ç¡®å®šæ€§ç»“æ„é‡Œï¼Œæ‰¾ä¸€ä¸ªå°½é‡å°èŒƒæ•°çš„$\Delta$èƒ½æŠŠ$I-\Delta M$æ¨åˆ°å¥‡å¼‚ï¼ˆä¸å¯é€†ï¼‰ï¼›å…¶â€œæœ€å°å¤§å°â€çš„å€’æ•°ï¼Œå°±æ˜¯$\mu$ã€‚\\
    å…³é”®ä»£æ•°äº‹å®: $\det(I - \Delta M) = 0$ å½“ä¸”ä»…å½“å­˜åœ¨éé›¶å‘é‡ $v$ ä½¿å¾— $(I - \delta M)v = 0$ï¼Œå³$\Delta Mv = v$ã€‚æ¢å¥è¯è¯´ï¼Œè‹¥è¾¾åˆ°å¥‡å¼‚ï¼Œåˆ™1æ˜¯$\Delta M$çš„ç‰¹å¾å€¼ï¼ˆè€Œä¸”å°±æ˜¯å®ç‰¹å¾å€¼1ï¼‰
\end{researchnote}
with $\mu_{\mathcal{K}}(M)=0$ if no $\Delta \in X_{\mathcal{K}}$ solves $\operatorname{det}(I-\Delta M)=0$.\\
In this paper we will be concerned directly with the computation of $\mu$ rather than how to use $\mu$ as a robustness analysis tool. For the reader unfamiliar with $\mu$-based techniques, a fairly comprehensive review is given in [7].

Whilst it is not at all obvious how to compute $\mu$ from (3), it is easy to obtain the following crude upper and lower bounds:\\
\hl{ç²—ç•Œï¼šä¸‹ç•Œæ¥è‡ªâ€œå®ç‰¹å¾å€¼â€èƒ½å¼•å‘ä¸ç¨³å®šï¼Œä¸Šç•Œæ¥è‡ªâ€œæŠŠç»“æ„å¿½ç•¥æ‰â€çš„æœ€å¤§å¥‡å¼‚å€¼}
\begin{equation*}
\rho_{R}(M) \leq \mu_{\mathcal{K}}(M) \leq \bar{\sigma}(M) \tag{4}
\end{equation*}
\hl{ä¸ºäº†æŠŠä¸Šé¢çš„ç²—ç•Œæ”¶ç´§ï¼Œå®šä¹‰$\mathcal{Q}_{\mathcal{K}}$å’Œ$\mathcal{D}_{\mathcal{K}}$è¿™ä¸¤ç»„å—å¯¹è§’çŸ©é˜µé›†åˆ}\\
å…¶ä¸­$\mathcal{Q}_{\mathcal{K}}$æ˜¯ä¸ç¡®å®šæ€§é›†åˆï¼Œç”¨äºç¼©å°ä¸ç¡®å®šæ€§çš„æœç´¢èŒƒå›´\\
$\mathcal{D}_{\mathcal{K}}$æ˜¯ç¼©æ”¾é›†åˆï¼Œç”¨äºå¯¹$M$åšç›¸ä¼¼å˜æ¢ï¼Œå› ä¸ºç›¸ä¼¼ç¼©æ”¾ä¸æ”¹å˜$\mu$ï¼Œä½†æ˜¯ä¼šæ”¹å˜$\bar{\sigma}()$çš„å¤§å°ã€‚å³$\mu_{\mathcal{K}}(M)=\mu_{\mathcal{K}}\left(D M D^{-1}\right)$ï¼Œä½†æ˜¯$\mu_{\mathcal{K}}(M) \leq \bar{\sigma}(M)$ï¼Œè€Œ$\mu_{\mathcal{K}}(D M D^{-1}) \leq \inf _{D \in \mathcal{D}_{\mathcal{K}}} \bar{\sigma}\left(D M D^{-1}\right)$ï¼Œåªéœ€è¦æ‰¾åˆ°è¿™ä¹ˆä¸€ä¸ª$D$èƒ½ä½¿å¾—$\inf _{D \in \mathcal{D}_{\mathcal{K}}} \bar{\sigma}\left(D M D^{-1}\right) \leq \bar{\sigma}(M)$ï¼Œè¿™æ ·å°±ç›¸å½“äºé€šè¿‡$D$å¯¹ä¸Šç•Œè¿›è¡Œäº†ç¼©å°ï¼Œä½¿å¾—ä¸Šç•Œæ›´ç´§ã€‚

To refine these bounds further we define the following sets of block diagonal matrices (also dependent on the underlying block structure):
\begin{researchnote}[author=JC, date=2025-10-23]
        \section*{$\mathcal{Q}_{\mathcal{K}}$}
        ä»æ˜¯å—å¯¹è§’ï¼Œä½†çº¦æŸä¸ºâ€œå•ä½æ¨¡/å•ä½é˜µâ€ï¼š
        \begin{itemize}
            \item é‡å¤å®æ ‡é‡å—å– $\delta^r_i\in[-1,1]$ï¼›
            \item é‡å¤å¤æ ‡é‡å—å– $\delta^c_i$ æ»¡è¶³ $\delta^{c*}_i \delta^c_i=1$ï¼ˆå³ $|\delta^c_i|=1$ï¼‰ï¼›
            \item æ¯ä¸ªå…¨å¤å— $\Delta^{C}_i$ å–\textbf{é…‰}ï¼ˆ$\Delta^{C*}_i\Delta^C_i=I$ï¼‰ã€‚
        \end{itemize}
            è¿™ç±» $\Delta$ å¯ä»¥ç†è§£ä¸º"ç›¸ä½/ç¬¦å·"çš„ç¼©æ”¾ï¼Œä¸æ”¹å˜å„å—çš„å¤§å°ï¼Œåªè½¬åŠ¨æ–¹å‘ã€‚
\end{researchnote}
\begin{equation*}
\mathcal{Q}_{\mathcal{K}}=\left\{\Delta \in X_{\mathcal{K}}: \delta_{i}^{r} \in[-1,1], \delta_{i}^{c *} \delta_{i}^{c}=1, \Delta_{i}^{C *} \Delta_{i}^{C}=I_{k_{m_{r}+m_{c}+i}}\right\} \tag{5}
\end{equation*}
\begin{researchnote}[author=JC, date=2025-10-23]
        \section*{$\mathcal{D}_{\mathcal{K}}$}
        ä¹Ÿæ˜¯æŒ‰å—å¯¹è§’çš„"æ­£å®šç¼©æ”¾"ï¼Œä½†å…è®¸åœ¨å¤æ ‡é‡å—å‰ä¹˜ä»¥ç›¸ä½ $e^{j\theta_i}$ï¼ˆ$\theta_i\in[-\pi/2,\pi/2]$ï¼‰ï¼Œåœ¨å®/å…¨å—ä¸Šç”¨æ­£çš„å®æ•°/æ­£å®šHermitiançŸ©é˜µåšå¹…åº¦ç¼©æ”¾ã€‚\\
        ç›´è§‚åœ°ï¼Œ$\mathcal D$ æ˜¯ä¸€ç»„å¯¹ $M$ åš"ç›¸ä¼¼å˜æ¢"çš„\textbf{æ¯”ä¾‹å°º}ï¼ˆscalingsï¼‰ï¼Œå°†éš¾çš„æ–¹å‘ç¼©å°ã€æ˜“çš„æ–¹å‘æ”¾å¤§ã€‚
\end{researchnote}
\begin{align*}
\mathcal{D}_{\mathcal{K}}= & \left\{\text { block } \operatorname { d i a g } \left(e^{j \theta_{1}} D_{1}, \cdots, e^{j \theta_{m_{r}}} D_{m_{r}}, D_{m_{r}+1}, \cdots\right.\right. \\
& \left.D_{m_{r}+m_{c}}, d_{1} I_{k_{m_{r}+m_{c}+1}}, \cdots, d_{m_{C}} I_{k_{m}}\right): \theta_{i} \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right] \\
& \left.0<D_{i}=D_{i}^{*} \in \mathcal{C}^{k_{i} \times k_{i}}, 0<d_{i} \in \mathcal{R}\right\} \tag{6}
\end{align*}


Note that for any $\Delta \in X_{\mathcal{K}}$ and any $D \in \mathcal{D}_{\mathcal{K}}, D \Delta=\Delta D$, and consequently we obtain the following lemma.\\
\textbf{Lemma 1:} For any matrix $M \in \mathcal{C}^{n \times n}$ and any compatible block structure $\mathcal{K}$, for all $D \in \mathcal{D}_{\mathcal{K}}$\\
\hl{$\mathcal{D}_{\mathcal{K}}$çš„ä½œç”¨ï¼šå¯ä»¥å¯¹$M$ç”¨$D$å…ˆåšç›¸ä¼¼å˜æ¢ï¼Œå†ç®—$\mu$}

\begin{equation*}
\mu_{\mathcal{K}}(M)=\mu_{\mathcal{K}}\left(D M D^{-1}\right) \tag{7}
\end{equation*}


Now to refine the lower bound we define the unit ball in the perturbation set as \\
\hl{å®šä¹‰ç»“æ„åŒ–å•ä½çƒä¸ç¡®å®šé›†$\mathbf{B} X_{\mathcal{K}}$}ï¼Œæ ¹æ®å®šä¹‰å°±æ˜¯æ—¢å±äºæ‰°åŠ¨çŸ©é˜µé›†åˆ$X_{\mathcal{K}}$ï¼Œåˆæ˜¯æœ€å¤§å¥‡å¼‚å€¼å°äºç­‰äº1çš„æ‰€æœ‰æ‰°åŠ¨çŸ©é˜µã€‚

\begin{equation*}
\mathbf{B} X_{\mathcal{K}}=\left\{\Delta \in X_{\mathcal{K}}: \bar{\sigma}(\Delta) \leq 1\right\} \tag{8}
\end{equation*}

The following lemma results almost immediately from the definition of $\mu$.\\
\textbf{Lemma 2:} For any matrix $M \in \mathcal{C}^{n \times n}$ and any compatible block structure $\mathcal{K}$
æ··åˆ$\mu$å®šä¹‰é‡Œï¼Œæˆ‘ä»¬åœ¨â€œç»“æ„åŒ–å•ä½çƒâ€å†…æœç´¢ä¼šä½¿$I - \Delta M$å¥‡å¼‚çš„$\Delta$ã€‚ç­‰ä»·åœ°ï¼Œ$\mu$å¯ä»¥å†™æˆâ€œåœ¨å•ä½çƒä¸Šçš„å®è°±åŠå¾„æœ€å¤§åŒ–â€ï¼š
\begin{equation*}
\mu_{\mathcal{K}}(M)=\max _{\Delta \in \mathbf{B} X_{\mathcal{K}}} \rho_{R}(\Delta M) \tag{9}
\end{equation*}
\hl{$\mu$åˆ†æé‡Œï¼Œè°±åŠå¾„ï¼ˆå°¤å…¶â€œå®è°±åŠå¾„â€ï¼‰æŠŠâ€œå¥‡å¼‚åŒ–é—®é¢˜â€è½¬æˆâ€œç‰¹å¾å€¼æœ€å¤§åŒ–é—®é¢˜â€}
è¿™æŠŠ"æœ€å°ä½¿å¤±ç¨³çš„ $\Delta$"ï¼ˆå®šä¹‰(3)ï¼‰æ”¹å†™æˆ"å•ä½çƒå†…è®©å®è°±åŠå¾„æœ€å¤§çš„ $\Delta$"â€”â€”æ›´åƒ"å¹¿ä¹‰çš„å¹‚æ³•"ç›®æ ‡ã€‚
\begin{researchnote}[author=JC, date=2025-10-23]
    \subsubsection*{è°±åŠå¾„}
        å¯¹ä»»æ„æ–¹é˜µ \( A \in \mathbb{C}^{n \times n} \)ï¼Œè°±åŠå¾„å®šä¹‰ä¸º
        \[
        \rho(A) = \max\{|\lambda| : \lambda \in \sigma(A)\},
        \]
        ä¹Ÿå°±æ˜¯ \( A \) çš„å…¨éƒ¨ç‰¹å¾å€¼æ¨¡é•¿ï¼ˆç»å¯¹å€¼ï¼‰é‡Œæœ€å¤§çš„é‚£ä¸ªã€‚
        å®è°±åŠå¾„\(\rho_R(A)\)æ˜¯ä»…åœ¨å®ç‰¹å¾å€¼é‡Œå–æœ€å¤§å€¼ï¼›è‹¥æ— å®ç‰¹å¾å€¼åˆ™è®°ä¸º0ã€‚\\
        å¦‚æœå­˜åœ¨$\Delta$èƒ½ä½¿$\det(I - \Delta M) = 0$ï¼Œé‚£è¯´æ˜å–è¯¥$\Delta$æ—¶ï¼Œ1æ˜¯$\Delta M$çš„ç‰¹å¾å€¼ï¼Œä½†æ˜¯1ä¸ä¸€å®šæ˜¯æœ€å¤§çš„å®ç‰¹å¾å€¼ï¼Œå› æ­¤\(\rho_R(\Delta M) \geq 1\)
    \subsubsection*{æ ‡å‡†åŒ–ï¼šæŠŠå®ç‰¹å¾å€¼$\gamma$é€šè¿‡å¯¹ä¸ç¡®å®šæ€§ç¼©æ”¾å˜æˆç‰¹å¾å€¼1}
        åè¿‡æ¥ï¼Œå¦‚æœæŸä¸ª \(\Delta\) æ»¡è¶³ \(\rho_R(\Delta M) = \gamma > 0\)ï¼Œå­˜åœ¨ \(v \neq 0\) ä½¿ \(\Delta M v = \gamma v\)ã€‚æŠŠ \(\Delta\) ç¼©æ”¾æˆ \(\Delta' = \frac{1}{\gamma} \Delta\)ï¼Œå°±å¾—åˆ°
        \[ \Delta' M v = \frac{1}{\gamma} \Delta M v = \frac{1}{\gamma} \gamma v = v \implies (I - \Delta' M) v = 0 \implies \det(I - \Delta' M) = 0. \]
\end{researchnote}
In light of (7) and (9), noting that $\mathcal{Q}_{\mathcal{K}} \subset \mathbf{B} X_{\mathcal{K}}$, we can refine the bounds in (4) to obtain the following lemma.

\begin{questionnote}[author=JC, date=2025-10-25]
    ä¸ºä»€ä¹ˆèƒ½ç¼©å°$\Delta$çš„å–å€¼èŒƒå›´åˆ°$Q_{\mathcal{K}}$è€Œä¸å½±å“ä¸‹ç•Œçš„æ±‚å–ï¼Œå³è¿˜æ˜¯$\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M)=\mu_{\mathcal{K}}(M)$\\
    åœ¨çº¿æ€§-åˆ†å¼çš„ç›®æ ‡ï¼ˆæˆ–ç”±ç‰¹å¾å€¼/ç‘åˆ©å•†è¯±å¯¼çš„ç›®æ ‡ï¼‰ä¸‹ï¼Œå¸¦èŒƒæ•°çº¦æŸçš„æœ€ä¼˜åŒ–å¸¸å¸¸åœ¨å•ä½çƒçš„æç‚¹ï¼ˆextreme pointsï¼‰æˆ–è¾¹ç•Œè¾¾åˆ°æœ€ä¼˜ï¼ˆè®ºæ–‡å¤ç°ä¸ä»£ç å®ç°ChatGPTï¼‰ï¼Œäºæ˜¯æˆ‘ä»¬è‡ªç„¶ä¼šæŠŠâ€œå•ä½çƒâ€è¿›ä¸€æ­¥ç¼©åˆ°å®ƒçš„è¾¹ç•Œæç‚¹é›†åˆä¸Šæœç´¢ã€‚è¿™å°±æ˜¯ $Q_{\mathcal{K}}$çš„é›å½¢
\end{questionnote}

\textbf{Lemma 3:} For any matrix $M \in \mathcal{C}^{n \times n}$ and any compatible block structure $\mathcal{K}$\\
\hl{ç”±äº$\mathcal{Q}_{\mathcal{K}} \subset \mathbf{B} X_{\mathcal{K}}$ï¼Œæ•…å¾—åˆ°å¤¹é€¼ç•Œ}
\begin{equation*}
\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M) \leq \mu_{\mathcal{K}}(M) \leq \inf _{D \in \mathcal{D}_{\mathcal{K}}} \bar{\sigma}\left(D M D^{-1}\right) \tag{10}
\end{equation*}
\hl{å«ä¹‰ï¼š}
    \begin{itemize}
        \item \textbf{ä¸‹ç•Œ}ï¼šåªç”¨"å•ä½æ¨¡/é…‰å—"çš„ $Q$ å»æ‰«ï¼Œæœ€å¤§åŒ– $\rho_R(QM)$ã€‚è¿™å¾ˆcheapï¼ˆ\hl{è®¡ç®—é‡å°ã€å®ç°ç®€å•ã€æ•°å€¼æˆæœ¬ä½}ï¼‰ï¼Œå¸¸ä½œä¸º\textbf{$\mu$ çš„å¯è®¡ç®—ä¸‹ç•Œ}ã€‚
        \item \textbf{ä¸Šç•Œ}ï¼šå…è®¸ç”¨"ç›¸ä½+æ­£å®šç¼©æ”¾"æŠŠ $M$ å˜å½¢ï¼Œæ±‚æœ€å°å¯èƒ½çš„æœ€å¤§å¥‡å¼‚å€¼ã€‚å³ç«¯æ˜¯ç»å…¸çš„ \textbf{Dâ€“(K) ç¼©æ”¾ä¸Šç•Œ}é›å½¢ï¼ˆè¿™é‡Œåªæ˜¯ $D$-ç¼©æ”¾ï¼‰ã€‚
    \end{itemize}

\begin{researchnote}[author=JC, date=2025-10-24]
    \subsection*{ä¸ºä»€ä¹ˆ$\mathbf Q_{\mathcal K}\subset \mathbf B X_{\mathcal K}$}
    å› ä¸ºæŒ‰å®šä¹‰ï¼Œ$\mathbf Q_{\mathcal K}$ ä¸­çš„æ¯ä¸ª $\Delta$ åŒæ—¶æ»¡è¶³ä¸¤ä»¶äº‹ï¼š

        \subsubsection*{å±äº $X_{\mathcal K}$}

        $\mathbf Q_{\mathcal K}$ ä¸ $X_{\mathcal K}$ å…·æœ‰ç›¸åŒçš„"å—å¯¹è§’"ç»“æ„ï¼ˆåŒæ ·çš„å—å°ºå¯¸ä¸æ’åˆ—ï¼‰ï¼Œåªæ˜¯å¯¹æ¯ä¸ªå—å†åŠ äº†æ›´å¼ºçš„"å•ä½æ¨¡/å•ä½é˜µ"çº¦æŸï¼ˆå¼(5)ï¼‰ã€‚å› æ­¤ $\mathbf Q_{\mathcal K}\subseteq X_{\mathcal K}$ã€‚

        \subsubsection*{æœ€å¤§å¥‡å¼‚å€¼ $\bar{\sigma}(\Delta)\le 1$}

        å¯¹å—å¯¹è§’çŸ©é˜µ $\Delta=\mathrm{blkdiag}(\Delta_1,\dots,\Delta_m)$ï¼Œå¥‡å¼‚å€¼é›†åˆå°±æ˜¯å„å—å¥‡å¼‚å€¼çš„å¹¶ï¼Œæ‰€ä»¥
        \[
        \bar{\sigma}(\Delta)=\max_i \bar{\sigma}(\Delta_i).
        \]
        è€Œåœ¨ $\mathbf Q_{\mathcal K}$ ä¸­ï¼š

        \begin{itemize}
            \item å®æ ‡é‡å— $\delta_i^r\in[-1,1]\Rightarrow \bar{\sigma}(\delta_i^r I)=|\delta_i^r|\le 1$ï¼›
            \item å¤æ ‡é‡å— $|\delta_i^c|=1\Rightarrow \bar{\sigma}(\delta_i^c I)=|\delta_i^c|=1$ï¼›
            \item å…¨å¤å—å–\textbf{é…‰}çŸ©é˜µ $\Delta_i^C$ï¼ˆ$\Delta_i^{C*}\Delta_i^C=I$ï¼‰$\Rightarrow$ æ‰€æœ‰å¥‡å¼‚å€¼éƒ½ç­‰äº 1ï¼Œå› è€Œ $\bar{\sigma}(\Delta_i^C)=1$ã€‚
        \end{itemize}

        äºæ˜¯ $\bar{\sigma}(\Delta)=\max_i \bar{\sigma}(\Delta_i)\le 1$ã€‚

        \subsubsection*{ç»“è®º}

        æŠŠä¸Šè¿°ä¸¤ç‚¹åˆåœ¨ä¸€èµ·ï¼šæ¯ä¸ª $\Delta\in\mathbf Q_{\mathcal K}$ éƒ½æ»¡è¶³"$\Delta\in X_{\mathcal K}$ ä¸” $\bar{\sigma}(\Delta)\le 1$"ï¼Œè¿™æ­£æ˜¯
        \[
        \mathbf B X_{\mathcal K}=\{\Delta\in X_{\mathcal K}:\bar{\sigma}(\Delta)\le 1\}
        \]
        çš„å®šä¹‰ã€‚å› æ­¤
        \[
        \boxed{\mathbf Q_{\mathcal K}\subset \mathbf B X_{\mathcal K}}
        \]
        æˆç«‹ã€‚

        ï¼ˆè‹¥è€ƒè™‘çŸ©å½¢"å…¨å¤å—"ï¼ŒæŠŠçº¦æŸå†™æˆå³é…‰/å·¦é…‰å¦‚ $\Delta_i^{C*}\Delta_i^C=I$ æˆ– $\Delta_i^C\Delta_i^{C*}=I$ ä¹Ÿæ˜¯ $\bar{\sigma}(\Delta_i^C)=1$ï¼›æœ¬æ–‡ä¸­å·²è¯´æ˜ä¸ºç®€æ´èµ·è§æŠŠå…¨å¤å—å–ä¸ºæ–¹é˜µï¼Œå› æ­¤ä¸Šé¢çš„è®ºè¯ç›´æ¥æˆç«‹ã€‚ï¼‰
\end{researchnote}
We introduce one further piece of notation. For any two vectors $x, y \in \mathcal{C}^{n}$, partition $x$ and $y$ according to the block structure as
\\\hl{å¯¹ä»»æ„å‘é‡è¿›è¡ŒæŒ‰ä¹‹å‰çš„ä¸ç¡®å®šæ€§å—ç»“æ„åˆ†è§£æˆä¸‹åˆ—å½¢å¼}

\begin{align*}
& x=\left[\begin{array}{lllllllll}
x_{r_{1}}^{T} & \cdots & x_{r_{m_{r}}}^{T} & x_{c_{1}}^{T} & \cdots & x_{c_{m_{c}}}^{T} & x_{C_{1}}^{T} & \cdots & x_{C_{m_{C}}}^{T}
\end{array}\right]^{T} \\
& y=\left[\begin{array}{llllllll}
y_{r_{1}}^{T} & \cdots & y_{r_{m_{r}}}^{T} & y_{c_{1}}^{T} & \cdots & y_{c_{m_{c}}}^{T} & y_{C_{1}}^{T} & \cdots
\end{array} y_{C_{m_{C}}}^{T}\right]^{T} \tag{11}
\end{align*}


where $x_{r_{i}}, y_{r_{i}} \in \mathcal{C}^{k_{i}}, x_{c_{i}}, y_{c_{i}} \in \mathcal{C}^{k_{m}+i}, x_{C_{i}}, y_{C_{i}} \in \mathcal{C}^{k m_{r}+m_{c}+i}$. These will be referred to as the "block components" of $x$ and $y$, and we define the "nondegeneracy" assumption to be that for every $i$ (in the appropriate set), $\left|y_{r_{i}}^{*} x_{r_{i}}\right| \neq 0,\left|y_{c_{i}}^{*} x_{c_{i}}\right| \neq 0,\left|y_{C_{i}}\right|\left|x_{C_{i}}\right| \neq 0$.\\
\hl{éé€€åŒ–å‡è®¾ï¼šä¸ºäº†åé¢ç®—æ³•è®¡ç®—è¿‡ç¨‹ä¸­çš„åˆ†æ¯éƒ½ä¸ä¸º0}

\section*{III. Lower Bound as a Maximization}
In this section we show that the lower bound for the mixed case (10) holds with equality, and hence it is sufficient to consider the complex uncertainties on their boundary. Note, however, that the definition of $\mathcal{Q}_{K}$ requires us to search over the full range of the real perturbations. The following lemma is taken from [1].

Lemma 4 [1]: Let $p: \mathcal{C}^{k} \rightarrow \mathcal{C}$ be a (multivariable) polynomial and define $\beta=\min \left\{|z|_{\infty}: p(z)=0\right\}$, then there exists a $z \in \mathcal{C}^{k}$ such that $p(z)=0$ and for every $i,\left|z_{i}\right|=\beta$.

\begin{researchnote}[author=JC, date=2025-10-23]
    \subsubsection*{å®šç†1æçº²æŒˆé¢†}
        (12)å¼è¯´æ˜äº†äºŒè€…çš„ç›¸ç­‰æ€§ï¼Œå³æˆ‘å¯ä»¥é€šè¿‡è®¡ç®—$\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M)$æ¥å¾—åˆ°$\mu_{\mathcal{K}}(M)$ã€‚ä¹Ÿå³æˆ‘åªéœ€è¦åœ¨â€œå•ä½æ¨¡/é…‰â€çš„å—å¯¹è§’é›†åˆ$\mathcal{Q}_{\mathcal{K}}$ä¸Šåšæœ€å¤§åŒ–ï¼Œå°±èƒ½å¾—åˆ°ç²¾ç¡®çš„$\mu$ï¼ˆä¸ä»…ä»…æ˜¯ä¸‹ç•Œï¼‰ã€‚å¯ä»¥åªåœ¨\( Q_{\mathcal K}\)é‡Œåšæœç´¢ï¼Œä¸å¿…åœ¨æ•´ä¸ª\(\mathbf B X_{\mathcal K}\)é‡Œæœç´¢ã€‚
    \subsubsection*{å¯¹å®šç†çš„ç†è§£}
        è¦è®© $I-\Delta M$ å¥‡å¼‚ä¸” $\|\Delta\|$ æœ€å°ï¼Œæœ€ä½³ $\Delta$ ä¼šæŠŠæ¯ä¸ªå¯æ§çš„å—éƒ½â€œæ¨åˆ°å•ä½çƒè¾¹ç•Œâ€ï¼›æŠŠå°ºåº¦ $\beta$ æ‹¿å‡ºæ¥ï¼Œå°±å¾—åˆ°ä¸€ä¸ªâ€œçº¯ç›¸ä½/é…‰â€çš„å—å¯¹è§’çŸ©é˜µ $Q$ï¼Œå°† $M$ çš„å®è°±åŠå¾„æ¨åˆ°\(\mu\)ã€‚
\end{researchnote}
This is now used to prove the main result of the section.\\
\hl{æš‚æ—¶æ²¡çœ‹å…·ä½“è¯æ˜ï¼Œå…ˆå¤ç°äº†å†è¯´ï¼Œç¡®å®šè¿™ä¸ªè¯æ˜æ–¹æ³•é‡ä¸é‡è¦ï¼Œæˆ–è€…è¯´èƒ½ä¸èƒ½ç”¨åˆ°è‡ªå·±çš„è®ºæ–‡é‡Œ}
\textbf{Theorem 1:} For any matrix $M \in \mathcal{C}^{n \times n}$ and any compatible block structure $\mathcal{K}$
\begin{equation*}
\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M)=\mu_{\mathcal{K}}(M) \tag{12}
\end{equation*}
\textbf{Proof:} It is trivial from (10) if $\mu_{\kappa}(M)=0$. So assume \hl{$\mu_{\mathcal{K}}(M)=\beta>0$}, and this value is achieved for some perturbation $\hat{\Delta}$, i.e., $\operatorname{det}(I-\hat{\Delta} M)=0$ and $\bar{\sigma}(\hat{\Delta}) \leq \frac{1}{\beta}$. Now fix the real perturbations at these "optimal" values ( $\delta_{i}^{r}=\hat{\delta}_{i}^{r}, i=1, \cdots, m_{r}$ with $\left|\hat{\delta}_{i}^{r}\right| \leq \frac{1}{\beta}$ ). Then allow the complex part of $\Delta$ to vary, and consider minimizing $\bar{\sigma}(\Delta)$ subject to $\operatorname{det}(I-\Delta M)=0$. Performing a singular value\\
decomposition (SVD) on $\Delta$, we obtain $\operatorname{det}(I-U \Sigma V M)=0$ where $U$ and $V$ are (block diagonal) unitary matrices and

$$
\begin{gathered}
\Sigma=\operatorname{diag}\left(\hat{\delta}_{1}^{r} I_{k_{1}}, \cdots \hat{\delta}_{m_{r}}^{r} I_{k_{m_{r}}}, \delta_{1}^{c} I_{k_{m_{r}+1}}, \cdots\right. \\
\left.\delta_{m_{c}}^{c} I_{k_{m_{r}+m_{c}}}, \gamma_{1}^{c}, \cdots, \gamma_{k}^{c}\right)
\end{gathered}
$$

with $k=\sum_{i=m_{r}+m_{c}+1}^{m} k_{i}$. This is a polynomial in $\delta_{1}^{c}, \cdots$, $\delta_{m_{c}}^{c}, \gamma_{1}^{c}, \cdots, \gamma_{k}^{c}$ and so applying Lemma 4 we have a solution with $\left|\hat{\delta}_{1}^{c}\right|=\cdots=\left|\hat{\delta}_{m_{c}}^{c}\right|=\left|\hat{\gamma}_{1}^{c}\right|=\cdots=\left|\hat{\gamma}_{k}^{c}\right|=\frac{1}{\hat{\beta}}$ and $\hat{\beta} \geq \beta$. Now suppose $\hat{\beta}>\beta$, say $\hat{\beta}=\beta+\epsilon$ for some $\epsilon>0$, then since the roots of a polynomial are continuous functions of the coefficients, we can find a $\delta>0$ so that

$$
\begin{aligned}
\left|\delta_{i}^{r}-\hat{\delta}_{i}^{r}\right|<\delta, i=1, \cdots, m_{r} \Rightarrow & \left|\delta_{i}^{c}-\hat{\delta}_{i}^{c}\right|<\frac{\epsilon}{2}, i=1, \cdots, m_{c} \\
& \left|\gamma_{i}^{c}-\hat{\gamma}_{i}^{c}\right|<\frac{\epsilon}{2}, i=1, \cdots, k
\end{aligned}
$$

Then, move each $\left|\delta_{i}^{r}\right|$ down by $\frac{\delta}{2}$, and we can find a $\Delta$ solving $\operatorname{det}(I-\Delta M)=0$ with $\bar{\sigma}(\Delta)<\frac{1}{\beta}$ contradicting the definition of $\mu$. Thus $\hat{\beta}=\beta$, and it is now easy to check that for this solution $\beta \hat{\Delta}=\hat{Q} \in \mathcal{Q}_{K}$ with $\rho_{R}(\hat{Q} M)=\beta=\mu_{K}(M)$.

\section*{IV. Characterization of a Maximum Point}
ç°åœ¨å·²ç»å°†é—®é¢˜è½¬åŒ–æˆäº†ä¸‹å¼ï¼Œæœ¬èŠ‚è¦è§£å†³çš„æ˜¯ï¼šå³è¾¹æ˜¯éå‡¹æœ€å¤§åŒ–ï¼Œä¸€èˆ¬ç®—æ³•åªèƒ½æ‰¾åˆ°å±€éƒ¨æœ€å¤§å€¼ï¼Œå› æ­¤æœ¬èŠ‚ç»™å‡º\hl{â€œä¸€ä¸ªç‚¹æ˜¯å±€éƒ¨æå¤§å€¼â€çš„åˆ¤åˆ«æ¡ä»¶}ï¼Œä»è€Œï¼š
\begin{itemize}
    \item çŸ¥é“è¿­ä»£åˆ°ä»€ä¹ˆæ—¶å€™ç®—æ˜¯å±€éƒ¨ç»“æŸï¼ˆåˆæ ¼çš„å±€éƒ¨æå¤§å€¼ï¼‰
    \item æ ¹æ®æ­¤åˆ¤æ–­æ¡ä»¶æ„é€ â€œå—å¯¹é½/ç¼©æ”¾â€æ›´æ–°æ³•åˆ™
\end{itemize}
We are interested in computing $\mu_{\mathcal{K}}(M)$, which by (9) and (12) is given by

$$
\mu_{\mathcal{K}}(M)=\max _{\Delta \in \mathbf{B} \bar{X}_{\mathcal{K}}} \rho_{R}(\Delta M)=\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M)
$$

For reasons of tractability we choose to consider the problem $\max _{Q \in \mathcal{Q}_{\mathcal{K}}} \rho_{R}(Q M)$. However, since this is a nonconcave problem we will in general only be able to find local maxima, and hence we will obtain a lower bound for $\mu_{\mathcal{K}}(M)$ (which is the global maximum). We would like this lower bound be "tight" (i.e., close to $\mu$ ) and so wish to rule out the maxima of $\rho_{R}(Q M)$ which we know are only local. Thus we only consider $Q \in \mathcal{Q}_{\mathcal{K}}$ which are local maxima of $\rho_{R}(Q M)$ with respect not only to $Q \in \mathcal{Q}_{\kappa}$ but also to $Q \in \mathbf{B} X_{K}$. In this section we will develop a characterization of such local maxima.

Note that for any $Q \in \mathcal{Q}_{\mathcal{K}}$ and any $\Delta \in \mathbf{B} X_{\mathcal{K}}, Q \Delta \in \mathbf{B} X_{\mathcal{K}}$ and $\Delta Q \in \mathbf{B} X_{\kappa}$. Now suppose some matrix $Q \in \mathcal{Q}_{\kappa}$ achieves a local maximum of $\rho_{R}(Q M)$ over $Q \in \mathbf{B} X_{K}$. Then it is easy to show that the matrix $\hat{M}:=Q M$ has a local maximum of $\rho_{R}(\hat{Q} \hat{M})$ over $\hat{Q} \in \mathbf{B} X_{\mathcal{K}}$ at $\hat{Q}=I$. However, since the real elements of $Q$ are not restricted to be on their boundary, we can say more than this. For any matrix $Q \in \mathcal{Q}_{K}$ [see (5)] define the index sets
\begin{questionnote}[author=JC, date=2025-10-27]
    \subsection*{ä¸ºä»€ä¹ˆè¦åˆ†\(\mathcal{J}\)ï¼Œ\(\hat{\mathcal{J}}\)å¹¶å¼•å…¥\(\hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})\)}\\
    è‡ªå·±æ€»ç»“ï¼š
    \begin{itemize}
        \item è¿™ä¸€æ­¥çš„å°±æ˜¯ä¸ºäº†è®©åŸæ¥ä¸å¯å¾®çš„æ ‡é‡å—å¯å¾®
        \item é—®é¢˜æœ¬è´¨æ˜¯å®æ ‡é‡å—çš„æœ€ä¼˜ç‚¹ä¸€èˆ¬æ˜¯åœ¨è¾¹ç•Œå¤„ï¼Œè€Œä¸”åªèƒ½å–å®æ•°ï¼Œä¸èƒ½åƒå¤å—ä¸€æ ·æ—‹è½¬ï¼Œå¯¼è‡´æœ€ä¼˜ç‚¹å¤„ä¹Ÿæ˜¯è¾¹ç•Œç‚¹å¤„æ²¡æœ‰åŠæ³•ç»§ç»­æ±‚å¯¼
    \end{itemize}

        \subsection*{é—®é¢˜æœ¬è´¨ï¼šå®æ ‡é‡å—ã€Œå¡åœ¨ Â±1ã€å¯¼è‡´å‡½æ•°ä¸å¯å¾®}

        å®Œå…¨æ­£ç¡® ğŸ‘

        ä½ è¿™å¥è¯å…¶å®å·²ç»æŠ“åˆ°äº†è¿™ä¸€æ­¥çš„\textbf{æ ¸å¿ƒåŠ¨æœº}ã€‚æˆ‘æ¥ç”¨æœ€é€šä¿—çš„æ–¹å¼æŠŠå®ƒè®²æ¸…æ¥šï¼š

        åœ¨ $\mu$-é—®é¢˜çš„ç»“æ„åŒ–ä¸ç¡®å®šé›†ä¸­ï¼Œ

        \begin{itemize}
        \item å¤å—ã€å…¨å¤å—éƒ½æ˜¯\textbf{å¹³æ»‘çš„}ï¼ˆå®ƒä»¬å¯ä»¥è¿ç»­æ—‹è½¬æˆ–ç¼©æ”¾ï¼Œå¥‡å¼‚å€¼è¿ç»­å˜åŒ–ï¼‰ï¼›
        \item ä½†\textbf{å®æ ‡é‡å—}åªèƒ½å–å®æ•°ï¼Œè€Œä¸”åœ¨é›†åˆ
        \[
        \mathcal{Q}_{\mathcal{K}} = \{\delta_i^r \in [-1,1],\ |\delta_i^c| = 1,\ \Delta_i^{C*}\Delta_i^C = I\}
        \]
        é‡Œï¼Œæœ€ä¼˜ç‚¹é€šå¸¸å‡ºç°åœ¨ \textbf{è¾¹ç•Œ} $(|\delta_i^r| = 1)$ã€‚
        \end{itemize}

        å½“æˆ‘ä»¬æƒ³åœ¨è¿™ä¸ªé›†åˆä¸Šåšã€Œæ–¹å‘å¯¼æ•°ã€æˆ–ã€Œä¸€é˜¶æ¡ä»¶ã€æ—¶ï¼Œè¾¹ç•Œç‚¹å°±ä¼šå‡ºé—®é¢˜â€”â€”å› ä¸ºä½ æ²¡æ³•å†å¾€â€œå¤–â€å¾®è°ƒï¼›å‡½æ•°åœ¨é‚£ç‚¹å˜æˆäº†ä¸€ä¸ª\textbf{ä¸å¯å¾®çš„â€œå°–è§’â€}ã€‚

        ç›´è§‚ç±»æ¯”ï¼š

        \begin{quote}
        æƒ³åœ¨ $[-1,1]$ ä¸Šæ±‚ $f(x)$ çš„æå¤§å€¼ï¼Œå¦‚æœæœ€ä¼˜åœ¨ $x=1$ï¼Œé‚£å³å¯¼æ•°ä¸å­˜åœ¨ï¼ˆå†å¾€å³å°±å‡ºç•Œäº†ï¼‰ã€‚
        \end{quote}

        \subsection*{è§£å†³åŠæ³•ï¼šäººä¸ºè®©å®ƒ"ç¨å¾®èƒ½åŠ¨"}

        äºæ˜¯è®ºæ–‡å¼•å…¥äº†ï¼š

        \begin{itemize}
        \item ä¸¤ä¸ªé›†åˆï¼š
        \begin{itemize}
        \item $\mathcal{J}(Q)$ï¼šé‚£äº›ã€Œå·²ç»è´´è¾¹ã€çš„å®å—ï¼›
        \item $\hat{\mathcal{J}}(Q)$ï¼šé‚£äº›è¿˜åœ¨ä¸­é—´çš„å®å—ï¼›
        \end{itemize}
        \item ç„¶åæŠŠçº¦æŸé›†åˆæ”¾å®½æˆ
        \[
        \widehat{\mathbf{B}}\Delta_\varepsilon(\mathcal{J},\hat{\mathcal{J}})
        \]
        â€”â€”å…è®¸è¾¹ç•Œå— $|\delta_i^r|$ ç¨å¾®å¤§ä¸€ç‚¹ï¼ˆä¾‹å¦‚ $1+\varepsilon$ï¼‰ã€‚
        \end{itemize}

        è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨æ¯ä¸ªæ–¹å‘ä¸Šéƒ½â€œè½»è½»åŠ¨ä¸€ä¸‹â€ï¼Œäºæ˜¯æ‰€æœ‰å—çš„å˜åŒ– $\dot{\Delta}$ éƒ½æ˜¯\textbf{å¯å¾®çš„}ï¼Œå¯ä»¥è®¡ç®—å¯¼æ•° $\dot{\lambda}(0)$ å¹¶å†™å‡ºå¿…è¦æ¡ä»¶ã€‚

        ç­‰æ¨å¯¼å®Œä¸€é˜¶æ¡ä»¶ï¼ˆå—å¯¹é½/ç¼©æ”¾ï¼‰åï¼Œå†è®© $\varepsilon \to 0^+$ï¼Œå›åˆ°åŸæ¥çš„çº¦æŸè¾¹ç•Œï¼Œç»“æœä¸å˜ã€‚

        \subsection*{æ¢æˆä¸€å¥è¯æ€»ç»“}

        âœ… è¿™ä¸€æ­¥ç¡®å®å°±æ˜¯ä¸ºäº†\textbf{è®©é‚£äº›æœ¬æ¥"å¡æ­»"çš„å®æ ‡é‡å—å˜å¾—å¯å¾®ã€å¯åˆ†æ}ï¼Œä»è€Œèƒ½ç»Ÿä¸€åœ°å†™å‡ºã€Œæ–¹å‘å¯¼æ•° $\leq 0$ã€çš„æ¡ä»¶ã€‚

        \subsection*{å†å½¢è±¡ä¸€ç‚¹çš„æ¯”å–»}

        æƒ³è±¡ï¼š

        \begin{itemize}
        \item å…¨å¤å—æ˜¯ä¸€ä¸ªã€Œåœ†ã€ï¼šä»»ä½•æ–¹å‘éƒ½èƒ½æ»‘åŠ¨ã€‚
        \item å®æ ‡é‡å—æ˜¯ã€Œçº¿æ®µã€ï¼šä¸¤ç«¯ï¼ˆÂ±1ï¼‰æ˜¯å°–è§’ï¼Œæ— æ³•ç»§ç»­æ»‘ã€‚
        \end{itemize}

        ä¸ºäº†æ±‚"æå¤§ç‚¹çš„æ–œç‡ä¸º 0"ï¼Œä½ å¾—å…ˆæŠŠé‚£æ ¹çº¿æ®µçš„ç«¯ç‚¹\textbf{ç£¨æˆåœ†è§’}ï¼Œåˆ†æå®Œä¹‹åå†æŠŠåœ†è§’ç£¨å¹³å›æ¥ã€‚è¿™å°±æ˜¯å¼•å…¥ $\widehat{\mathbf{B}}\Delta_\varepsilon$ çš„é€»è¾‘ã€‚

        \textbf{æ‰€ä»¥ï¼Œæ˜¯çš„ï¼šè¿™ä¸€æ•´æ­¥çš„ç›®çš„ï¼Œå°±æ˜¯è®©é‚£äº›å¤„åœ¨è¾¹ç•Œï¼ˆÂ±1ï¼‰çš„å®æ ‡é‡å—æš‚æ—¶"å¯å¾®"ï¼Œä¿è¯æˆ‘ä»¬èƒ½å®šä¹‰æ–¹å‘å¯¼æ•°ã€å»ºç«‹ä¸€é˜¶å¿…è¦æ¡ä»¶ï¼ˆå³å—å¯¹é½/ç¼©æ”¾æ¡ä»¶ï¼‰ã€‚}

\end{questionnote}

\begin{align*}
& \mathcal{J}(Q)=\left\{i \leq m_{r}:\left|\delta_{i}^{r}\right|=1\right\}  \tag{13}\\
& \hat{\mathcal{J}}(Q)=\left\{i \leq m_{r}:\left|\delta_{i}^{r}\right|<1\right\} \tag{14}
\end{align*}


and define the allowable perturbation set


\begin{align*}
\hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})= & \left\{\Delta \in X_{\mathcal{K}}:\left|\delta_{i}^{r}\right| \leq 1, i \in \mathcal{J},\left|\delta_{i}^{r}\right|<1+\epsilon,\right. \\
& i \in \hat{\mathcal{J}},\left|\delta_{i}^{c}\right| \leq 1, i=1, \cdots, m_{c}, \\
& \left.\bar{\sigma}\left(\Delta_{i}^{C}\right) \leq 1, i=1, \cdots, m_{C}\right\} . \tag{15}
\end{align*}


We see that for sufficiently small $\epsilon>0$, for any $Q \in \mathcal{Q}_{\mathcal{K}}$ and any $\Delta \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}(Q), \hat{\mathcal{J}}(Q)), Q \Delta \in \mathbf{B} X_{\kappa}$ and $\Delta Q \in \mathbf{B} X_{\kappa}$. The point of all this is that if some matrix $Q \in \mathcal{Q}_{\mathcal{K}}$ achieves a local maximum of $\rho_{R}(Q M)$ over $Q \in \mathbf{B} X_{K}$, then the matrix $\hat{M}:=Q M$ has a local maximum of $\rho_{R}(\hat{Q} \hat{M})$ over $\hat{Q} \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}(Q), \hat{\mathcal{J}}(Q))$ (for some $\epsilon>0$ ) at $\hat{Q}=I$ (and in fact the converse is true, provided we assume that for every $i, \delta_{i}^{r} \neq 0$ ).

Before proving the main result we need some preliminary lemmas. The following two linear algebra lemmas are due to Packard [2].

Lemma 5 [2]: Let $y \in \mathcal{C}^{n}$ and $x \in \mathcal{C}^{n}$ be nonzero vectors. Then there exists a $d \in \mathcal{R}, d>0$ such that $y=d x$ iff $\operatorname{Re}\left(y^{*} G x\right) \leq 0$ for every $G \in \mathcal{C}^{n \times n}$ satisfying $G+G^{*} \leq 0$.

Lemma 6 [2]: Let $y \in \mathcal{C}^{n}$ and $x \in \mathcal{C}^{n}$ be nonzero vectors. Then there exists a Hermitian, positive definite $D \in \mathcal{C}^{n \times n}$ such that $y=D x$ iff $y^{*} x \in \mathcal{R}$ and $y^{*} x>0$.

Now define the closed half-space in the complex plane as, for some scalar $\psi \in \mathcal{R}$


\begin{equation*}
H^{\psi}=\left\{z: \operatorname{Re}\left(e^{j \psi} z\right) \leq 0\right\} \tag{16}
\end{equation*}


Then we have the following elementary linear algebra lemmas.\\
Lemma 7: Given any set of complex scalars $\mathcal{Z}=\left\{z_{i}: i=\right. 1, \cdots, m\}$ and any real scalar $\psi$, then $\mathcal{Z} \subset H^{\psi}$ iff $\sum_{i=1}^{m} \alpha_{i} z_{i} \in H^{\psi}$ for all real nonnegative scalars $\alpha_{i}, i=1, \cdots, m$.

Proof $(\Leftarrow)$ : For each $z_{k}$ choose $\alpha_{k}=1$ and $\alpha_{i}=0$ for $i \neq k$

$$
(\Rightarrow) \quad \operatorname{Re}\left(e^{j \psi} \sum_{i=1}^{m} \alpha_{i} z_{i}\right)=\sum_{i=1}^{m} \alpha_{i} \operatorname{Re}\left(e^{j \psi} z_{i}\right) \leq 0 .
$$

Lemma 8: Given any set of complex scalars $\mathcal{Z}=\left\{z_{i}: i=\right. 1, \cdots, m\}$, define $\lambda:=\sum_{i=1}^{m} \alpha_{i} z_{i}$ where $\alpha_{i}, i=1, \cdots, m$ are real nonnegative scalars. Then $\lambda$ is not real and positive for any choice of the above $\alpha_{i}$ 's iff $\mathcal{Z} \subset H^{\psi}$ for some $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$.

Proof ( $\Leftarrow$ ): By Lemma $7 \mathcal{Z} \subset H^{\psi}$ implies $\lambda \in H^{\psi}$, and hence $\operatorname{Re}\left(e^{j \psi} \lambda\right) \leq 0$. Suppose $\lambda$ is real and positive. Then this implies $\operatorname{Re}\left(e^{j \psi}\right) \leq 0$ which means $\psi \notin\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$, which is a contradiction.\\
$(\Rightarrow)$ : Assume $\lambda$ is never real and positive. Now suppose $\mathcal{Z} \not \subset H^{\psi}$ for any $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$. First choose $\psi=0$. Then, we must have at least one $z \in \mathcal{Z}$ with $\operatorname{Re}(z)>0$. Now we choose $\hat{z}_{1}$ as the element with $\operatorname{Re}(z)>0$ having minimum $|\arg (z)|$ (which must be nonzero). Now choose $\psi=\arg \left(\hat{z}_{1}\right)$ and define $\hat{\psi}=\frac{\pi}{2}-\psi$. Then, since $\hat{z}_{1} \in H^{\hat{\psi}}$, we must have a (nonzero) $\hat{z}_{2} \in \mathcal{Z}$ with $\hat{z}_{2} \notin H^{\hat{\psi}}$. Suppose

$$
\hat{z}_{1}=r_{1}(\cos \psi+j \sin \psi), \quad \hat{z}_{2}=r_{2}(\cos \phi+j \sin \phi)
$$

Then by our choice of $\hat{z}_{1}$ and $\hat{z}_{2}$, straightforward trigonometry yields the following facts: $|\sin \phi| \geq|\sin \psi|, \operatorname{sgn}(\sin \phi)=-\operatorname{sgn}(\sin \psi)$, $|\cos \phi| \leq|\cos \psi|$, and if $|\cos \phi|=|\cos \psi|$, then $\cos \phi=\cos \psi$. Now choose $\hat{\alpha}_{1}=\frac{1}{r_{1}|\sin \psi|}$ and $\hat{\alpha}_{2}=\frac{1}{r_{2}|\sin \phi|}$. Then we have

$$
\hat{\lambda}=\hat{\alpha}_{1} \hat{z}_{1}+\hat{\alpha}_{2} \hat{z}_{2}=\frac{\cos \psi}{|\sin \psi|}+\frac{\cos \phi}{|\sin \phi|}
$$

Thus $\hat{\lambda}$ is real and positive, which is a contradiction.\\
Putting all this together we obtain the following alignment condition.
\begin{researchnote}[author=JC, date=2025-10-23]
    \subsection*{å®šç†2æçº²æŒˆé¢†ï¼šç»™å‡ºæœ€å¤§å€¼çš„åˆ»ç”»}
        ä»å·¦ç‰¹å¾å‘é‡å’Œå³ç‰¹å¾å€¼å‘é‡å¯¹é½çš„è§’åº¦ç»™å‡ºäº†æœ€å¤§å€¼çš„åˆ»ç”»\\
        å®šç†2çš„ç»“è®ºè¯´æ˜äº†ï¼Œåœ¨é€‚å½“å‡è®¾ä¸‹ï¼ˆä¸»å¯¼å®ç‰¹å¾å€¼å•ã€éé€€åŒ–ç­‰ï¼‰ï¼Œè‹¥ $Q=I$ æ˜¯ $\rho_R(QM)$ çš„å±€éƒ¨æå¤§ï¼Œåˆ™\textbf{å¿…é¡»}å­˜åœ¨\[y = e^{j\psi}Dx,\]
        å…¶ä¸­ $(x,y)$ æ˜¯è¯¥å®ç‰¹å¾å€¼çš„å³/å·¦ç‰¹å¾å‘é‡ï¼Œ$D$ æ˜¯\textbf{æŒ‰å—å¯¹è§’çš„æ­£å®šç¼©æ”¾}ï¼ˆå±äº $\mathcal D_{\mathcal K}$ï¼‰ï¼Œ$\psi\in(-\tfrac{\pi}{2},\tfrac{\pi}{2})$ æ˜¯ä¸€ä¸ªå…¨å±€ç›¸ä½ã€‚
        å¯¹ä¸åŒå—è¿˜ç»™å‡ºæ›´ç»†çš„\textbf{ç›¸ä½æ‰‡åŒº}é™åˆ¶ï¼ˆå®å—è¾¹ç•Œ/å†…éƒ¨ã€å¤æ ‡é‡å—ã€å…¨å¤å—åˆ†åˆ«æ€ä¹ˆ"å¯¹é½"ï¼‰ã€‚

        \textbf{ä¸€å¥è¯}ï¼šåœ¨æ¯ä¸ªä¸ç¡®å®šæ€§å—ä¸Šï¼Œ$y$ å’Œ $x$ å¿…é¡»åœ¨ä¸€ä¸ªæ­£å®šç¼©æ”¾å\textbf{æ–¹å‘ä¸€è‡´ï¼ˆalignmentï¼‰}ï¼Œå¦åˆ™ä¸å¯èƒ½æ˜¯æå¤§ç‚¹ã€‚
        \subsection*{å®ƒå¸¦æ¥çš„ä¸‰ä»¶"ç¡¬å·¥å…·"}

            \subsubsection*{å¯åˆ¤æ€§ï¼ˆåœæœºåˆ¤æ®ï¼‰}

            \begin{itemize}
            \item ä½ åšä»»ä½•ä¸Šå‡è¿­ä»£ï¼ˆå¹‚æ³•ã€å—å¹‚æ³•ã€skewed-$\mu$ è¿­ä»£ï¼‰ï¼Œå½“åˆ°è¾¾æŸä¸ª $Q$ æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨ $D,\psi$ ä½¿ $y=e^{j\psi}Dx$ï¼ˆæŒ‰å—æ£€æŸ¥å¼(24)é‚£å¥—å…³ç³»ï¼‰ã€‚
            \item è‹¥æ»¡è¶³ $\Rightarrow$ è¾¾åˆ°\textbf{åˆæ ¼çš„å±€éƒ¨æå¤§}ï¼›è‹¥ä¸æ»¡è¶³ $\Rightarrow$ è¿˜å­˜åœ¨èƒ½\textbf{ç»§ç»­ä¸Šå‡}çš„å¯è¡Œæ–¹å‘ï¼Œä¸èƒ½åœã€‚
            \end{itemize}

            \subsubsection*{å¯æ„é€ çš„ä¸Šå‡æ–¹å‘}

            \begin{itemize}
            \item å®šç†çš„é€†å‘æ€è·¯ï¼šè‹¥æœªå¯¹é½ï¼Œå°±èƒ½åœ¨å¯¹åº”å—ä¸Šæ„é€ ä¸€ä¸ªå…è®¸çš„"æ–¹å‘" $G$ ä½¿ $\Re(y^*Gx)>0$ï¼ˆä¸€é˜¶å¯¼æ•°ä¸ºæ­£ï¼‰ï¼Œä»è€Œç»§ç»­æŠŠ $\rho_R$ æ¨é«˜â€”â€”è¿™ç›´æ¥ç»™å‡ºäº†\textbf{æ›´æ–°æ³•åˆ™}ï¼ˆè§ä¸‹ Â§4ï¼‰ã€‚
            \end{itemize}

            \subsubsection*{ä¸ $D$-ç¼©æ”¾ä¸Šç•Œçš„"æ¡¥"}

            \begin{itemize}
            \item ç»“è®ºé‡Œå‡ºç°çš„ $D\in\mathcal D_{\mathcal K}$ ä¸ä¸Šç•Œç«¯çš„ $D$-ç¼©æ”¾æ˜¯\textbf{åŒä¸€ç±»å¯¹è±¡}ã€‚
            \item å¯ç¤ºï¼šå³ä½¿ä½ åªåš"ä¸‹ç•Œæœ€å¤§åŒ–"ï¼Œåˆ°è¾¾åˆæ ¼æå¤§ç‚¹æ—¶ï¼Œéšå«ç€ä¸€ä¸ªå¥½çš„ $D$-ç¼©æ”¾æŠŠ $(x,y)$ å¯¹é½ï¼›è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆå·¥ç¨‹ä¸Š $(D)$â€“$(K)$ èƒ½æŠŠä¸Šä¸‹ç•Œæ‹‰è¿‘ï¼Œä¹ŸæŒ‡å¯¼å¦‚ä½•åˆå§‹åŒ–/æ¸©å¯åŠ¨ $D$ã€‚
            \end{itemize}
            \subsubsection*{è¿­ä»£æ­¥éª¤}
            æ¯ä¸€æ­¥ï¼š

            \begin{enumerate}
            \item é€‰ä¸€ä¸ª $Q\in\mathcal Q_{\mathcal K}$ï¼Œç®— $QM$ çš„\textbf{ä¸»å®ç‰¹å¾å¯¹} $(\lambda_0,x,y)$ï¼›
            \item \textbf{æŒ‰å—"å¯¹é½"æ›´æ–°}ï¼ˆæ¥è‡ªå®šç† 2 çš„å¿…è¦æ¡ä»¶ï¼‰ï¼š
            \begin{itemize}
            \item å®æ ‡é‡å—ï¼š$\delta_i^r \leftarrow \operatorname{sign}\big(\Re(y_{r_i}^*x_{r_i})\big)$ï¼ˆå†…éƒ¨å—è¶‹å‘ $\pm j$ æ‰‡åŒºè¾¹ç•Œï¼‰ï¼›
            \item å¤æ ‡é‡å—ï¼š$\delta_i^c \leftarrow \dfrac{y_{c_i}^*x_{c_i}}{|y_{c_i}^*x_{c_i}|}$ï¼›
            \item å…¨å¤å—ï¼š$\Delta_i^C \leftarrow \dfrac{y_{C_i}x_{C_i}^*}{|y_{C_i}|,|x_{C_i}|}$ã€‚
            \end{itemize}
            \item ç”¨æ–°å—ç»„æˆ $Q_{\text{new}}$ï¼Œè‹¥ $\rho_R(Q_{\text{new}}M)$ æå‡ä¸æ˜æ˜¾æˆ–å¯¹é½æ¡ä»¶å·²æ»¡è¶³ $\Rightarrow$ \textbf{åœ}ï¼›å¦åˆ™ç»§ç»­ã€‚
            \end{enumerate}

\end{researchnote}
\textbf{Theorem 2:} Suppose the matrix $M \in \mathcal{C}^{n \times n}$ has a distinct real eigenvalue $\lambda_{0}>0$ with right and left eigenvectors, $x$ and $y$, respectively, satisfying the nondegeneracy assumption. Further, suppose that $\rho_{R}(M)=\lambda_{0}$. Then if the function $\rho_{R}(Q M)$ attains a local maximum over the set $Q \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})$ (for some $\epsilon>0$ ) at $Q=I$, then there exists a matrix $D \in \mathcal{D}_{\mathcal{K}}$, with $\theta_{i}= \pm \frac{\pi}{2}$ for every $i \in \hat{\mathcal{J}}$, and a real scalar $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$ such that $y=e^{j \psi} D x$.

Proof: First we parameterize the perturbation set. Consider $G \in X_{\mathcal{K}}$ with


\begin{gather*}
G=\text { block } \operatorname{diag}\left(g_{1}^{r} I_{k_{1}}, \cdots, g_{m_{r}}^{r} I_{k_{m_{r}}}, g_{1}^{c} I_{k_{m_{r}+1}}, \cdots\right. \\
\left.g_{m_{c}}^{c} I_{k_{m_{r}+m_{c}}}, G_{1}^{C}, \cdots, G_{m_{C}}^{C}\right) \tag{17}
\end{gather*}


and the added restrictions


\begin{align*}
g_{i}^{r} \leq 0, \quad i \in \mathcal{J} \\
\operatorname{Re}\left(g_{i}^{c}\right) \leq 0, \quad i=1, \cdots, m_{c}  \tag{18}\\
G_{i}^{C}+G_{i}^{C *} \leq 0, \quad i=1, \cdots, m_{C}
\end{align*}


Now it can be shown that for some $\delta>0$, the set of all matrices $E(t):=(I+G t)(I-G t)^{-1}$ for $G$ as above and $t$ such that\\
$t \bar{\sigma}(G) \in\left[\begin{array}{ll}0 & \delta\end{array}\right)$ is an open neighborhood of $\hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})$ about $E(0)=I$. So now define the matrix $R(t):=E(t) M$. Then it is clear that $\rho_{R}(Q M)$ has attained a local maximum over the set $Q \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})$ at $Q=I$ iff $\rho_{R}(R(t))$ has attained a local maximum over $t \geq 0$ at $t=0$ for arbitrary $G$ as above.

Since $R(0)=M$ has a distinct real eigenvalue $\lambda_{0}$, we have (for some nonempty interval about the origin) an analytic function $\lambda(t)$, with $\lambda(0)=\lambda_{0}$, and $\lambda(t)$ an eigenvalue of $R(t)$. Thus we can differentiate to obtain


\begin{equation*}
\dot{\lambda}(0)=y^{*} \dot{R}(0) x=2 y^{*} G M x=2 \lambda_{0} y^{*} G x \tag{19}
\end{equation*}


In block notation this becomes


\begin{equation*}
\dot{\lambda}(0)=2 \lambda_{0}\left(\sum_{i=1}^{m_{r}} g_{i}^{r} y_{r_{i}}^{*} x_{r_{i}}+\sum_{i=1}^{m_{c}} g_{i}^{c} y_{c_{i}}^{*} x_{c_{i}}+\sum_{i=1}^{m_{C}} y_{C_{i}}^{*} G_{i}^{C} x_{C_{i}}\right) \tag{20}
\end{equation*}


Define the set of points


\begin{align*}
\mathcal{Z}=\left\{z_{i}: i=1, \cdots, m\right\}= & \left\{g_{i}^{r} y_{r_{i}}^{*} x_{r_{i}}: i=1, \cdots, m_{r}\right\} \\
& \cup\left\{g_{i}^{c} y_{c_{i}}^{*} x_{c_{i}}: i=1, \cdots, m_{c}\right\} \\
& \cup\left\{y_{C_{i}}^{*} G_{i}^{C} x_{C_{i}}: i=1, \cdots, m_{C}\right\} \tag{21}
\end{align*}


with the obvious identification for the elements $z_{i}$. Now since we are at a maximum point we have that $\dot{\lambda}(0)$ is never real and positive. Thus, noting that we may independently scale $g_{i}^{r}, g_{i}^{c}, G_{i}^{C}$ by arbitrary nonnegative scalars and still satisfy (18), applying Lemma 8 to (20) and (21) gives that this is true iff $\mathcal{Z} \subset H^{\psi}$ for some $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$ for each $G \in X_{\kappa}$ satisfying (18). Furthermore, since any summation of $G$ 's satisfying (18) also satisfies (18), Lemma 8 gives that this is true iff there is one $H^{\psi}$ which works for every $G$, i.e., there exists $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$ such that $\mathcal{Z} \subset H^{\psi}$ for all $G \in X_{\kappa}$ satisfying (18). From the definition of $H^{\psi}$ in (16), and $G$ in (17), (18), this is equivalent to


\begin{align*}
& \operatorname{Re}\left(e^{j \psi} g_{i}^{r} y_{r_{i}}^{*} x_{r_{i}}\right) \leq 0 \\
& \quad \text { for all } g_{i}^{r} \in \mathcal{R} \text { with } g_{i}^{r} \leq 0, i=1, \cdots, m_{r} \\
& \operatorname{Re}\left(e^{j \psi} g_{i}^{r} y_{r_{i}}^{*} x_{r_{i}}\right) \leq 0 \\
& \quad \text { for all } g_{i}^{r} \in \mathcal{R}, i \in \hat{\mathcal{J}} \\
& \operatorname{Re}\left(e^{j \psi} g_{i}^{c} y_{c_{i}}^{*} x_{c_{i}}\right) \leq 0 \\
& \quad \text { for all } g_{i}^{c} \in \mathcal{C} \text { with } \operatorname{Re}\left(g_{i}^{c}\right) \leq 0, i=1, \cdots, m_{c} \\
& \operatorname{Re}\left(e^{j \psi} y_{C_{i}}^{*} G_{i}^{C} x_{C_{i}}\right) \leq 0 \\
& \quad \text { for all } G_{i}^{C} \text { with } G_{i}^{C}+G_{i}^{C *} \leq 0, i=1, \cdots, m_{C} \tag{22}
\end{align*}


for some $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$. It is now easy to check that the above conditions may be equivalently expressed as


\begin{align*}
\operatorname{Re}\left(e^{j \psi} y_{r_{i}}^{*} x_{r_{i}}\right) \geq 0, & i=1, \cdots, m_{r} \\
\operatorname{Re}\left(e^{j \psi} y_{r_{i}}^{*} x_{r_{i}}\right)=0, & i \in \hat{\mathcal{J}} \\
e^{j \psi} y_{c_{i}}^{*} x_{c_{i}} \in(0 \infty), & i=1, \cdots, m_{c} \\
\operatorname{Re}\left(e^{j \psi} y_{C_{i}}^{*} G_{i}^{C} x_{C_{i}}\right) \leq 0, & \text { for all } G_{i}^{C} \text { with } G_{i}^{C}+G_{i}^{C *} \leq 0, \\
& i=1, \cdots, m_{C} \tag{23}
\end{align*}


Since the scalar $e^{j \psi}$ terms may simply be absorbed into one of the vectors, we can apply Lemmas 5 and 6 to each block component of $x$ and $y$ to obtain the equivalent conditions

\[
\begin{array}{lr}
y_{r_{i}}=e^{j \psi} e^{j \theta_{i}} D_{i} x_{r_{i}}, & 0<D_{i}=D_{i}^{*}, \theta_{i} \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right] \\
& i=1, \cdots, m_{r} \\
y_{r_{i}}=e^{j \psi} e^{j \theta_{i}} D_{i} x_{r_{i}}, & 0<D_{i}=D_{i}^{*}, \theta_{i}= \pm \frac{\pi}{2}, i \in \hat{\mathcal{J}} \\
y_{c_{i}}=e^{j \psi} D_{i} x_{c_{i}}, & 0<D_{i}=D_{i}^{*}, i=1, \cdots, m_{c} \\
y_{C_{i}}=e^{j \psi} d_{i} x_{C_{i}}, & 0<d_{i} \in \mathcal{R}, i=1, \cdots, m_{C} \tag{24}
\end{array}
\]

Stacking these relations in matrix form yields $y=e^{j \psi} D x$ with $D$ of the required form.

Remarks: Note from the proof that we immediately have a partial converse to Theorem 2, namely that if $y=e^{j \psi} D x$ under the above assumptions, then no directional derivative (in the above sense) of the eigenvalue achieving $\rho_{R}(Q M)$ over the set $Q \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}, \hat{\mathcal{J}})$ is real and positive at $Q=I$.

\section*{V. A Decomposition at $\mu$}
Theorem 2 gives us a characterization of a maximum point of $\rho_{R}(Q M)$ in terms of an alignment of the right and left eigenvectors of $Q M$. This leads directly to the following decomposition.

\begin{researchnote}[author=JC, date=2025-10-27]
    \subsection*{å®šç†3æçº²æŒˆé¢†ï¼šæŠŠæå¤§ç‚¹åˆ»ç”»æˆä¸€ä¸ª\(Q\)å·¦ä¹˜ï¼Œ\(D\)ä¸¤è¾¹ç¼©æ”¾çš„æ ‡å‡†ç‰¹å¾å€¼åˆ†è§£}
     

\end{researchnote}


\textbf{Theorem 3:} Suppose $Q \in \mathcal{Q}_{\kappa}$ achieves a local maximum of $\rho_{R}(Q M)$ over $Q \in \mathbf{B} X_{K}$ and that the eigenvalue achieving $\rho_{R}(Q M)$, denoted $\beta$, is distinct and positive. Then, if the right and left eigenvectors of $Q M$, denoted $x$ and $y$, respectively, satisfy the nondegeneracy assumption, there exists a matrix $D \in \mathcal{D}_{\mathcal{K}}$ with $D^{2} \in \mathcal{D}_{\mathcal{K}}$ and $\theta_{i}= \pm \frac{\pi}{4}$ for $i \in \hat{\mathcal{J}}(Q)$ such that


\begin{align*}
Q D M D^{-1}(D x) & =\beta D x \\
\left(x^{*} D^{*}\right) Q D^{*} M\left(D^{*}\right)^{-1} & =\beta x^{*} D^{*} \tag{25}
\end{align*}


with $\beta \leq \mu_{\mathcal{K}}(M)$. Furthermore, if the above maximum is global, then $\beta=\mu_{\kappa}(M)$.

Proof: Since $Q \in \mathcal{Q}_{\mathcal{K}}$ is a local maximum of $\rho_{R}(Q M)$ over $Q \in \mathbf{B} X_{\mathcal{K}}$, the matrix $\hat{M}:=Q M$ achieves a local maximum of $\rho_{R}(\hat{Q} \hat{M})$ over $\hat{Q} \in \hat{\mathbf{B}} \Delta_{\epsilon}(\mathcal{J}(Q), \hat{\mathcal{J}}(Q))$ (for some $\epsilon>0$ ) at $\hat{Q}=I$. Now apply Theorem 2 to conclude $y=e^{j \psi} \hat{D} x$ with $\hat{D} \in \mathcal{D}_{\mathcal{K}}$ and $\hat{\theta}_{i}= \pm \frac{\pi}{2}$ for $i \in \hat{\mathcal{J}}(Q)$, then define $D$ as the unique matrix such that $D \in \mathcal{D}_{\mathcal{K}}$ and $D^{2}=\hat{D}$. Substitution of this into the right and left eigenvalue equations of $Q M$ and simple manipulations (note that for any $Q \in \mathcal{Q}_{\mathcal{K}}$ and any $D \in \mathcal{D}_{\mathcal{K}}, Q$ and $D$ commute) yield the results in (25). Finally, note from Theorem 1 that we have $\beta \leq \mu_{\kappa}(M)$, and if the above maximum is global then $\beta=\mu_{\mathcal{K}}(M)$.

Remarks: Employing simple manipulations of (25) yields a partial converse of this theorem. If we have a decomposition as in (25) with $\beta$ real and positive and $x$ nonzero, then we have that $\beta$ is an eigenvalue of $Q M$ with right and left eigenvectors, $x$ and $y$, respectively [thus $\beta$ is a lower bound for $\left.\mu_{\mathcal{K}}(M)\right]$, where $y=r e^{j \psi} D^{2} x$ with $D$ as above, $r$ a positive real scalar (which we could thus absorb into $D$ ), and $\psi \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$. Thus defining $\hat{D}=r D^{2}$ we have $y=e^{j \psi} \hat{D} x$ with $\hat{D}$ as in Theorem 2 and $\psi \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$. If we add the further technical assumption that we are not in the special case of $\theta_{i}= \pm \frac{\pi}{4}$ for all $i=1, \cdots, m_{r}$ and $m_{c}=0, m_{C}=0$, then we have $\psi \in\left(-\frac{\pi}{2} \frac{\pi}{2}\right)$.

Thus, we (almost) always have a decomposition at $\mu$ of the form (25), and any such decomposition gives us a lower bound for $\mu$. Now we reformulate this condition into a set of vector equations.\\
å¼•ç†9çš„ä½œç”¨ï¼š\hl{æŠŠå®šç†3çš„åˆ†è§£ç­‰ä»·é‡è¿°ä¸ºæ˜“äºå®ç°çš„å‘é‡æ–¹ç¨‹ç»„(27)}ï¼Œä¾¿äºæ„é€ /éªŒè¯ä¸æ•°å€¼è¿­ä»£\\
Lemma 9: Suppose we have matrices $Q \in \mathcal{Q}_{\kappa}$ with $\delta_{i}^{r} \neq 0$ for $i=1, \cdots, m_{r}$ and $\hat{D} \in \mathcal{D}_{\mathcal{K}}$ with $\hat{D}^{2} \in \mathcal{D}_{\mathcal{K}}$ and $\hat{\theta}_{i}= \pm \frac{\pi}{4}$ for $i \in \hat{\mathcal{J}}(Q)$. Then we have a nonzero vector $\hat{x}$ and a real positive scalar $\beta$ such that


\begin{align*}
Q \hat{D} M \hat{D}^{-1}(\hat{D} \hat{x}) & =\beta \hat{D} \hat{x} \\
\left(\hat{x}^{*} \hat{D}^{*}\right) Q \hat{D}^{*} M\left(\hat{D}^{*}\right)^{-1} & =\beta \hat{x}^{*} \hat{D}^{*} \tag{26}
\end{align*}


iff there exists a matrix $D \in \mathcal{D}_{\mathcal{K}}$ with $\theta_{i}= \pm \frac{\pi}{2}$ for $i \in \hat{\mathcal{J}}(Q)$ and nonzero vectors $b, a, z, w$ such that

\[
\begin{array}{rlrl}
M b & =\beta a & M^{*} z & =\beta w \\
b & =Q a & b & =D^{-1} w \\
z & =Q^{*} Q D a & z & =Q^{*} w \tag{27}
\end{array}
\]

Proof ( $\Rightarrow$ ): Define $x=\hat{D} \hat{x}$ and $b, a, z, w$ as $b=\hat{D}^{-1} x, a= \hat{D}^{-1} Q^{-1} x, z=\hat{D} Q^{*} x, w=\hat{D} x$. Finally, define $D=\hat{D}^{2}$; the result follows.\\
$(\Leftarrow)$ : Define $\hat{D}$ as the unique matrix $\hat{D} \in \mathcal{D}_{\mathcal{K}}$ such that $\hat{D}^{2}=D$, and $\hat{x}=b$, the result follows directly.

\section*{VI. A Power Algorithm for the Lower Bound}
\hl{å¼€å‘ä¸€ç§ç®—æ³•è®¡ç®—å¼•ç†9çš„è§£}
In light of Lemma 9, the problem of computing a lower bound for $\mu_{\mathcal{K}}(M)$ is reduced to one of finding a solution to the set of equations in (27) which gives us a decomposition as in (25). We would like to develop an algorithm for computing such a solution. First note that if we partition $b, a, z, w$ compatibly with the block structure as in (11), then the set of constraint equations

$$
\begin{array}{ll}
b=Q a & b=D^{-1} w \\
z=Q^{*} Q D a & z=Q^{*} w
\end{array}
$$

can be broken down into a series of $m$ similar independent constraint equations on the block components (since $Q$ and $D$ are block diagonal). These equations are of three types corresponding to a repeated real scalar block, a repeated complex scalar block, or a full complex block. We now consider a generic constraint of each type. The following two lemmas are due to Packard [2].

\begin{researchnote}[author=JC, date=2025-10-27]
    å¯¹ä¸Šè¿°çš„å››æ¡çº¦æŸæ–¹ç¨‹è¿›è¡Œåˆ’åˆ†ï¼Œå¯ä»¥åˆ†è§£ä¸ºä¸€ç³»åˆ—å…³äºå—åˆ†é‡çš„ç›¸ä¼¼ç‹¬ç«‹çº¦æŸæ–¹ç¨‹ï¼ˆå› ä¸ºQå’ŒDæ˜¯å—å¯¹è§’çš„ï¼‰ï¼Œå››æ¡å…¨å±€çº¦æŸå¯ä»¥è¢«é€å—ç‹¬ç«‹å¤„ç†ã€‚è¿™äº›æ–¹ç¨‹åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼Œåˆ†åˆ«å¯¹åº”é‡å¤çš„å®æ ‡é‡å—ã€é‡å¤çš„å¤æ ‡é‡å—æˆ–å®Œå…¨å¤å—ã€‚ç°åœ¨æˆ‘ä»¬è€ƒè™‘æ¯ç§ç±»å‹çš„ä¸€èˆ¬çº¦æŸã€‚
\end{researchnote}
\hl{é‡å¤å¤æ ‡é‡å—æƒ…å½¢ä¸‹çš„çº¦æŸæ–¹ç¨‹}
Lemma 10 (Repeated Complex Scalar Block [2]): Let $b, a, z, w \in \mathcal{C}^{k}$ be nonzero vectors with $a^{*} w \neq 0$. Then there exists a complex scalar $q$ with $|q|=1$ and a complex matrix $D \in \mathcal{C}^{k \times k}$ with $0<D=D^{*}$ such that

$$
\begin{array}{ll}
b=q a & b=D^{-1} w \\
z=q^{*} q D a & z=q^{*} w
\end{array}
$$

if and only if


\begin{equation*}
z=\frac{w^{*} a}{\left|w^{*} a\right|} w \quad b=\frac{a^{*} w}{\left|a^{*} w\right|} a \tag{28}
\end{equation*}

\hl{é‡å¤å¤æ ‡é‡å—æƒ…å½¢ä¸‹çš„çº¦æŸæ–¹ç¨‹}
Lemma 11 (Full Complex Block [2]): Let $b, a, z, w \in \mathcal{C}^{k}$ be nonzero vectors. There exists a complex matrix $Q \in \mathcal{C}^{k \times k}$ with $Q^{*} Q=I_{k}$ and a real positive scalar $d$ such that

$$
\begin{array}{ll}
b=Q a & b=d^{-1} w \\
z=Q^{*} Q d a & z=Q^{*} w
\end{array}
$$

if and only if


\begin{equation*}
z=\frac{|w|}{|a|} a \quad b=\frac{|a|}{|w|} w \tag{29}
\end{equation*}


Now we consider a repeated real scalar block, bearing in mind that we have additional constraints if the real perturbation is not on the boundary (i.e., for $i \in \hat{\mathcal{J}}(Q)$ ).

Lemma 12 (Repeated Real Scalar Block): Let $b, a, z, w \in \mathcal{C}^{k}$ be nonzero vectors with $a^{*} w \neq 0$. We have a real scalar $q$ with $|q| \leq 1$, a real scalar $\theta \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$, and a complex matrix $D \in \mathcal{C}^{k \times k}$ with $0<D=D^{*}$ such that

$$
\begin{array}{ll}
b=q a & b=e^{-j \theta} D^{-1} w \\
z=q^{*} q e^{j \theta} D a & z=q^{*} w
\end{array}
$$

with $\theta= \pm \frac{\pi}{2}$ for $|q|<1$ iff


\begin{equation*}
z=q w \quad b=q a \tag{30}
\end{equation*}


with

\[
\begin{array}{ll}
\operatorname{Re}\left(a^{*} w\right) \geq 0 & \text { for } q=1 \\
\operatorname{Re}\left(a^{*} w\right) \leq 0 & \text { for } q=-1 \\
\operatorname{Re}\left(a^{*} w\right)=0 & \text { for }|q|<1 \tag{31}
\end{array}
\]

Proof ( $\Rightarrow$ ): Immediately we have $z=q w$ and $b=q a$. Thus $a^{*} w=\frac{1}{q} b^{*} w=\frac{1}{q} e^{j \theta} w^{*}\left(D^{*}\right)^{-1} w$. Now $q=1$ implies $\arg \left(a^{*} w\right)=\theta$, and hence $\operatorname{Re}\left(a^{*} w\right) \geq 0$. Similarly, $q=-1$ implies $\arg \left(a^{*} w\right)=\theta+\pi$ and hence $\operatorname{Re}\left(a^{*} w\right) \leq 0$. Finally, $|q|<1$ implies $\arg \left(a^{*} w\right)=\theta$ or $\theta+\pi$ with $\theta= \pm \frac{\pi}{2}$. Thus $\arg \left(a^{*} w\right)= \pm \frac{\pi}{2}$, and so $\operatorname{Re}\left(a^{*} w\right)=0$.\\
$(\Leftarrow)$ : Immediately we have $b=q a$ and $z=q^{*} w$, and so $b^{*} w=q a^{*} w$. Denoting $\theta=\arg \left(b^{*} w\right)$, we see that for $q=1 \operatorname{Re}\left(a^{*} w\right) \geq 0$, which implies $\operatorname{Re}\left(b^{*} w\right) \geq 0$, and so $\theta \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$. Similarly for $q=-1 \operatorname{Re}\left(a^{*} w\right) \leq 0$, which implies $\operatorname{Re}\left(b^{*} w\right) \geq 0$, and so $\theta \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$. Finally for $|q|<1, \operatorname{Re}\left(a^{*} w\right)=0$ which implies $\operatorname{Re}\left(b^{*} w\right)=0$, and so $\theta= \pm \frac{\pi}{2}$. Now $b^{*}\left(e^{-j \theta} w\right)$ is real and positive, and so applying Lemma 6 we have a matrix $\hat{D}$ with $0<\hat{D}=\hat{D}^{*}$ such that $b=e^{-j \theta} \hat{D} w$. Define $D=\hat{D}^{-1}$, and we have $b=e^{-j \theta} D^{-1} w$ and $z=q^{*} w=q^{*} e^{j \theta} D b=q^{*} q e^{j \theta} D a$.

These lemmas now allow us (with a few technical assumptions) to eliminate matrices $Q$ and $D$ from (27). To avoid the notation becoming excessive, we consider a simple block structure with $m_{r}=m_{c}=m_{C}=1$ for the remainder of this section. We stress that this is purely for notational convenience, and the general formulas for an arbitrary block structure, as defined in Section II, are simply obtained by duplicating the appropriate formulas for each block. So given $\mathcal{K}=\left(k_{1}, k_{2}, k_{3}\right)$, the appropriate scaling sets become


\begin{align*}
\mathcal{Q}_{\text {sub }}= & \left\{\text { block } \operatorname{diag}\left(q^{r} I_{k_{1}}, q^{c} I_{k_{2}}, Q^{C}\right): q^{r} \in[-11],\right. \\
& \left.q^{c *} q^{c}=1, Q^{C *} Q^{C}=I_{k_{3}}\right\}  \tag{32}\\
\mathcal{D}_{\text {sub }}= & \left\{\text { block } \operatorname{diag}\left(e^{j \theta} D_{1}, D_{2}, d I_{k_{3}}\right): \theta \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right],\right. \\
& \left.0<D_{i}=D_{i}^{*} \in \mathcal{C}^{k_{i} \times k_{i}}, 0<d \in \mathcal{R}\right\} \tag{33}
\end{align*}


and we partition $b, a, z, w$ compatibly with this block structure as

\[
b=\left[\begin{array}{l}
b_{1}  \tag{34}\\
b_{2} \\
b_{3}
\end{array}\right], a=\left[\begin{array}{l}
a_{1} \\
a_{2} \\
a_{3}
\end{array}\right], z=\left[\begin{array}{l}
z_{1} \\
z_{2} \\
z_{3}
\end{array}\right], w=\left[\begin{array}{l}
w_{1} \\
w_{2} \\
w_{3}
\end{array}\right]
\]

where $b_{i}, a_{i}, z_{i}, w_{i} \in \mathcal{C}^{k_{i}}$. Then we obtain our final form of (27) as in the following theorem, which will form the basis of a power iteration to compute a lower bound for $\mu_{\mathcal{K}}(M)$.
\hl{å®šç†4ï¼šæ ¹æ®ä¸Šè¿°å¼•ç†ï¼Œå¾—åˆ°å¼ï¼ˆ27ï¼‰çš„æœ€ç»ˆå½¢å¼ï¼Œä¹Ÿæ˜¯å¹‚è¿­ä»£æ³•çš„åŸºç¡€}
\textbf{Theorem 4:} Suppose we have vectors $b, a, z, w \in \mathcal{C}^{n}$ partitioned as in (34) with $b_{i}, a_{i}, z_{i}, w_{i} \neq 0$ and $a_{1}^{*} w_{1}, a_{2}^{*} w_{2} \neq 0$. Then there exist matrices $Q \in \mathcal{Q}_{\text {sub }}$ and $D \in \mathcal{D}_{\text {sub }}$ and a positive real scalar $\beta$ such that

$$
\begin{array}{rlrl}
M b & =\beta a & M^{*} z & =\beta w \\
b & =Q a & b & =D^{-1} w \\
z & =Q^{*} Q D a & z & =Q^{*} w
\end{array}
$$

with $\theta \in\left[-\frac{\pi}{2} \frac{\pi}{2}\right]$, and $\theta= \pm \frac{\pi}{2}$ for $\left|q^{r}\right|<1$ iff


\begin{align*}
M b & =\beta a \\
z_{1} & =q w_{1} \quad z_{2}=\frac{w_{2}^{*} a_{2}}{\left|w_{2}^{*} a_{2}\right|} w_{2} \quad z_{3}=\frac{\left|w_{3}\right|}{\left|a_{3}\right|} a_{3}  \tag{35}\\
M^{*} z & =\beta w \\
b_{1} & =q a_{1} \quad b_{2}=\frac{a_{2}^{*} w_{2}}{\left|a_{2}^{*} w_{2}\right|} a_{2} \quad b_{3}=\frac{\left|a_{3}\right|}{\left|w_{3}\right|} w_{3}
\end{align*}


for some real scalar $q \in[-11]$ with

\[
\begin{array}{ll}
\operatorname{Re}\left(a_{1}^{*} w_{1}\right) \geq 0 & \text { for } q=1 \\
\operatorname{Re}\left(a_{1}^{*} w_{1}\right) \leq 0 & \text { for } q=-1  \tag{36}\\
\operatorname{Re}\left(a_{1}^{*} w_{1}\right)=0 & \text { for }|q|<1
\end{array}
\]

Proof: Apply Lemmas 10-12 to the appropriate block components.

Remarks: Since (35) and (36) are unaffected if we multiply $b$ and $a$ by an arbitrary positive real scalar $\alpha$, and $z$ and $w$ by an arbitrary positive real scalar $\gamma$, then in searching for solutions to these equations we may impose the additional restriction $|a|=|w|=1$.

Any solution to (35) and (36) immediately gives us a decomposition as in (25), and hence $\beta$ is a lower bound for $\mu_{\mathcal{K}}(M)$. We also note that under certain technical assumptions (as given), there always exists a solution to these equations with $\beta=\mu_{\mathcal{K}}(M)$. Since we would like to find the largest $\beta$ we can that solves (35) and (36), we now propose finding a solution to this system of equations via the following power iteration:


\begin{align*}
\tilde{\beta}_{k+1} a_{k+1} & =M b_{k} \\
z_{1_{k+1}} & =\tilde{q}_{k+1} w_{1_{k}} \quad z_{2_{k+1}}=\frac{w_{2_{k}}^{*} a_{2_{k+1}}}{\left|w_{2_{k}}^{*} a_{2_{k+1}}\right|} w_{2_{k}} \\
z_{3_{k+1}} & =\frac{\left|w_{3_{k}}\right|}{\left|a_{3_{k+1}}\right|} a_{3_{k+1}} \\
\hat{\beta}_{k+1} w_{k+1} & =M^{*} z_{k+1}  \tag{37}\\
b_{1_{k+1}} & =\hat{q}_{k+1} a_{1_{k+1}} \quad b_{2_{k+1}}=\frac{a_{2_{k+1}}^{*} w_{2_{k+1}}}{\left|a_{2_{k+1}}^{*} w_{2_{k+1}}\right|} a_{2_{k+1}} \\
b_{3_{k+1}} & =\frac{\left|a_{3_{k+1}}\right|}{\left|w_{3_{k+1}}\right|} w_{3_{k+1}}
\end{align*}


where $\tilde{q}_{k+1}$ and $\hat{q}_{k+1}$ evolve as

$$
\tilde{\alpha}_{k+1}=\operatorname{sgn}\left(\hat{q}_{k}\right) \frac{\left|b_{1_{k}}\right|}{\left|a_{1_{k+1}}\right|}+\operatorname{Re}\left(a_{1_{k+1}}^{*} w_{1_{k}}\right)
$$

If $\left|\tilde{\alpha}_{k+1}\right| \geq 1 \quad$ Then $\tilde{q}_{k+1}=\frac{\tilde{\alpha}_{k+1}}{\left|\tilde{\alpha}_{k+1}\right|} \quad$ Else $\tilde{q}_{k+1}=\tilde{\alpha}_{k+1}$


\begin{equation*}
\hat{\alpha}_{k+1}=\operatorname{sgn}\left(\tilde{q}_{k+1}\right) \frac{\left|b_{1_{k}}\right|}{\left|a_{1_{k+1}}\right|}+\operatorname{Re}\left(a_{1_{k+1}}^{*} w_{1_{k+1}}\right) \tag{38}
\end{equation*}


If $\left|\hat{\alpha}_{k+1}\right| \geq 1 \quad$ Then $\hat{q}_{k+1}=\frac{\hat{\alpha}_{k+1}}{\left|\hat{\alpha}_{k+1}\right|} \quad$ Else $\hat{q}_{k+1}=\hat{\alpha}_{k+1}$\\
and $\tilde{\beta}_{k+1}, \hat{\beta}_{k+1}$ are chosen positive real so that $\left|a_{k+1}\right|=\left|w_{k+1}\right|=1$.\\
It is now straightforward to verify that if the algorithm converges to some equilibrium point, then we satisfy the appropriate constraints on each block component; hence by Lemmas 10-12 we have nonzero vectors $b, a, z, w \in \mathcal{C}^{n}$, matrices $Q \in \mathcal{Q}_{\text {sub }}, D \in \mathcal{D}_{\text {sub }}$, and positive real scalars $\tilde{\beta}, \hat{\beta}$ such that

\[
\begin{array}{rlrl}
M b & =\tilde{\beta} a & M^{*} z & =\hat{\beta} w \\
b & =Q a & b & =D^{-1} w  \tag{39}\\
z & =Q^{*} Q D a & z & =Q^{*} w
\end{array}
\]

Thus if $\tilde{\beta}=\hat{\beta}$, then we satisfy (27) and so have a decomposition as in (25); hence $\tilde{\beta}$ is a lower bound for $\mu_{\mathcal{K}}(M)$ [associated with a local maximum of $\left.\rho_{R}(Q M)\right]$.

We note that if $\tilde{\beta} \neq \hat{\beta}$, then we have not found a decomposition as in (25). However, from (39) we find that $Q M b=\tilde{\beta} b$ and $w^{*} Q M=\hat{\beta} w^{*}$. Thus we have that both $\tilde{\beta}$ and $\hat{\beta}$ are real positive eigenvalues of $Q M$, and so by Lemma 3, $\max (\tilde{\beta}, \hat{\beta})$ still gives us a lower bound for $\mu_{\mathcal{K}}(M)$.

\section*{VII. Concluding Remarks}
The algorithm described here has been implemented in software and is commercially available as part of the $\mu$-Tools toolbox [3]. We now have a good deal of numerical experience with the algorithm on benchmark problems, and in addition the code has been used for a number of real engineering applications which are detailed elsewhere\\[0pt]
in the literature (e.g., see [8]). We have found that the algorithm typically performs very well in terms of convergence, accuracy of the resulting bound, and required computation. Space constraints preclude our including this material here, but we refer the interested reader to [9] and the references therein for a detailed numerical study of the algorithm performance as well as [10] for recent efforts at further enhancing the performance.

\begin{researchnote}[author=JC, date=2025-10-23]
    \subsubsection*{å‡ ä½•ç›´è§‰ç†è§£$\mu$çš„å«ä¹‰}
    ç³»ç»Ÿçš„ä¼ é€’å‡½æ•°çŸ©é˜µ$G(s)$ï¼Œè¦æƒ³åˆ¤æ–­è¿™ä¸ªç³»ç»Ÿçš„ç¨³å®šæ€§ï¼ˆå†…ç¨³å®šï¼‰ï¼Œéœ€è¦å°†$G(s)$è½¬æ¢ä¸ºçŠ¶æ€ç©ºé—´å½¢å¼ï¼Œè¿™ä¸ªå®ç°æœ€å¥½æ˜¯æœ€å°å®ç°ï¼ˆå³å®Œå…¨èƒ½æ§ä¸”å®Œå…¨èƒ½è§‚çš„ï¼‰ï¼Œå…¶ä¿è¯äº†æ²¡æœ‰é›¶æç‚¹å¯¹æ¶ˆã€‚\\
    è®¾ä¼ é€’å‡½æ•°çŸ©é˜µ$G(s)$çš„çŠ¶æ€ç©ºé—´æœ€å°å®ç°çš„ç³»ç»ŸçŸ©é˜µä¸º$A$ï¼Œåˆ™ç¨³å®šæ€§åˆ¤æ®ä¸ºï¼šå¦‚æœç³»ç»ŸçŸ©é˜µ$A$çš„æ‰€æœ‰ç‰¹å¾å€¼$\lambda_{k}$éƒ½æ»¡è¶³$Re(\lambda_{k})<0$ï¼Œåˆ™è¯¥ç³»ç»Ÿæ˜¯å†…ç¨³çš„ã€‚\\
    $A$çš„æ‰€æœ‰ç‰¹å¾å€¼$\lambda_{k}$æ˜¯é€šè¿‡æ±‚è§£ç‰¹å¾æ–¹ç¨‹\( \det(\lambda I - A) = 0 \)å¾—åˆ°çš„ã€‚\\


    $M$æ˜¯ä¸€ä¸ªæ ‡ç§°ç³»ç»Ÿçš„ä¼ é€’å‡½æ•°å¤çŸ©é˜µï¼Œ$\Delta$æ˜¯ä¸ç¡®å®šæ€§é›†åˆä¸­çš„å…¶ä¸­ä¸€ä¸ªæƒ…å†µã€‚æˆ‘ä»¬ç°åœ¨åˆ¤æ–­å«ä¸ç¡®å®šæ€§çš„ç³»ç»ŸçŸ©é˜µ$\Delta M$æ˜¯å¦ç¨³å®šã€‚
    è¦åˆ¤æ–­ä¸€ä¸ªç³»ç»Ÿæ˜¯å¦ç¨³å®šï¼Œå°±è¦çœ‹è¯¥ç³»ç»Ÿçš„çŸ©é˜µçš„ç‰¹å¾å€¼çš„å®éƒ¨æ˜¯å¦å°äº0ï¼Œå³çŸ©é˜µçš„ç‰¹å¾æ–¹ç¨‹ç‰¹å¾å¤šé¡¹å¼ä¸å­˜åœ¨å³åŠå¹³é¢é›¶ç‚¹ã€‚
    çŸ©é˜µ$\Delta M$çš„ç‰¹å¾å€¼$\lambda$å†³å®šç³»ç»Ÿæ˜¯å¦ç¢°åˆ°è¾¹ç•Œï¼Œ$\lambda$æ˜¯å¤æ•°ï¼Œå¦‚æœ$\lambda$çš„æ¨¡å°äº1ï¼Œåˆ™è¯¥
    \begin{itemize}
        \item è‹¥æ‰€æœ‰çš„ç‰¹å¾å€¼éƒ½åœ¨
    \end{itemize}
\end{researchnote}


\section*{Acknowledgment}
The authors would like to thank A. Packard for helpful discussions and M. Newlin for help in implementing the lower-bound software.

\section*{References}
[1] J. Doyle, "Analysis of feedback systems with structured uncertainty," IEE Proc., Part D, vol. 129, pp. 242-250, 1982.\\[0pt]
[2] A. Packard, M. K. H. Fan, and J. C. Doyle, "A power method for the structured singular value," in Proc. 27th Conf. Decision Contr., 1988, pp. 2132-2137.\\[0pt]
[3] G. J. Balas, J. C. Doyle, K. Glover, A. K. Packard, and R. S. Smith, The $\mu$ Analysis and Synthesis Toolbox. MathWorks and MUSYN, 1991.\\[0pt]
[4] M. K. H. Fan, A. L. Tits, and J. C. Doyle, "Robustness in the presence of mixed parametric uncertainty and unmodeled dynamics," IEEE Trans. Automat. Contr., vol. 36, pp. 25-38, 1991.\\[0pt]
[5] P. M. Young, M. P. Newlin, and J. C. Doyle, "Practical computation of the mixed $\mu$ problem," in Proc. Amer. Contr. Conf., 1992, pp. 2190-2194.\\[0pt]
[6] R. D. Braatz, P. M. Young, J. C. Doyle, and M. Morari, "Computational complexity of $\mu$ calculation," IEEE Trans. Automat. Contr., vol. 39, pp. 1000-1002, 1994.\\[0pt]
[7] A. K. Packard and J. C. Doyle, "The complex structured singular value," Automatica, vol. 29, pp. 71-109, 1993.\\[0pt]
[8] G. J. Balas and P. M. Young, "Control design for variations in structural natural frequencies," AIAA J. Guidance, Dynamics Contr., vol. 18, pp. 325-332, 1995.\\[0pt]
[9] P. M. Young, M. P. Newlin, and J. C. Doyle, " $\mu$ analysis with real parametric uncertainty," in Proc. 30th Conf. Decision Contr., 1991, pp. 1251-1256.\\[0pt]
[10] J. E. Tierno and P. M. Young, "An improved $\mu$ lower bound via adaptive power iteration," in 31st IEEE Conf. Decision Contr., 1992, pp. 3181-3186.

\section*{Correction to "Stability Conditions for Multiclass Fluid Queueing Networks"}
\section*{Dimitris Bertsimas, David Gamarnik, and John N. Tsitsiklis}
In the above-mentioned paper, ${ }^{1}$ the recommending Associate Editor line in the first paragraph of the footnote on p. 1618 should have read: "Recommended by Associate Editor, W.-B. Gong."

Manuscript received November 19, 1996.\\
D. Bertsimas is with the Sloan School of Management and Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA 02139 USA (e-mail: \href{mailto:dbertsim@ans.mit.edu}{dbertsim@ans.mit.edu}).\\
D. Gamarnik is with the Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA 02139 USA.\\
J. N. Tsitsiklis is with the Laboratory for Information and Decision Sciences and Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA 02139 USA.

Publisher Item Identifier S 0018-9286(97)01533-X.\\
${ }^{1}$ D. Bertsimas, D. Gamarkink, and J. N. Tsitsiklis, IEEE Trans. Automat. Contr., vol. 41, pp. 1618-1631, Nov. 1996.


\end{document}